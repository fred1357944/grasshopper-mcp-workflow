#!/usr/bin/env python3
"""
Claude Plan Generator - Layer 2 è¨ˆç•«ç”Ÿæˆå™¨
==========================================

ç•¶ Golden Knowledge ä¸å®Œå…¨åŒ¹é…æ™‚ï¼Œç”¨å–®æ¬¡ Claude èª¿ç”¨ç”ŸæˆåŸ·è¡Œè¨ˆç•«ã€‚

é—œéµè¨­è¨ˆ:
- çŸ¥è­˜æ³¨å…¥: å°‡ triplets + patterns + GUIDs æ³¨å…¥ prompt
- çµæ§‹åŒ–è¼¸å‡º: è¦æ±‚ Claude è¼¸å‡º JSON æ ¼å¼çš„ placement_info
- ä¸€æ¬¡å®Œæˆ: ä¸åšå¤šè¼ªå°è©±ï¼Œä¸€æ¬¡ç”Ÿæˆå®Œæ•´è¨ˆç•«

Usage:
    from grasshopper_mcp import ClaudePlanGenerator

    generator = ClaudePlanGenerator()
    plan = generator.generate(
        user_input="åšä¸€å€‹ 10x10 çš„ç¶²æ ¼çµæ§‹",
        partial_knowledge=knowledge
    )
"""

import json
from dataclasses import dataclass, field
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime


@dataclass
class ExecutionPlan:
    """åŸ·è¡Œè¨ˆç•«"""
    success: bool
    placement_info: Optional[Dict] = None
    components: List[Dict] = field(default_factory=list)
    connections: List[Dict] = field(default_factory=list)
    errors: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)
    generation_context: Dict = field(default_factory=dict)

    # Mermaid ç›¸é—œå±¬æ€§
    description: str = ""
    patterns_used: List[str] = field(default_factory=list)
    user_inputs: List[str] = field(default_factory=list)
    component_groups: Dict[str, List[Dict]] = field(default_factory=dict)

    def to_placement_info(self) -> Dict:
        """è½‰æ›ç‚º placement_info æ ¼å¼"""
        return self.placement_info or {
            "components": self.components,
            "connections": self.connections,
            "layout": {},
            "_meta": {
                "source": "claude_plan_generator",
                "generated_at": datetime.now().isoformat(),
                **self.generation_context
            }
        }


class ClaudePlanGenerator:
    """
    ä¸€æ¬¡æ€§ç”ŸæˆåŸ·è¡Œè¨ˆç•«

    çŸ¥è­˜æ³¨å…¥ç­–ç•¥:
    1. é€£æ¥ä¸‰å…ƒçµ„ (çµ±è¨ˆé »ç‡) - å‘Šè¨´ Claude å“ªäº›é€£æ¥æœ€å¸¸è¦‹
    2. é€£æ¥æ¨¡å¼ (é å®šç¾© wiring) - å‘Šè¨´ Claude æ¨™æº–é€£æ¥æ–¹å¼
    3. çµ„ä»¶ GUID (é¿å…è¡çª) - ç¢ºä¿ä½¿ç”¨æ­£ç¢ºçš„çµ„ä»¶ç‰ˆæœ¬
    4. æ¨™æº–å·¥ä½œæµç¨‹æ¨¡æ¿ - ç¢ºä¿ç”Ÿæˆå®Œæ•´æµç¨‹
    """

    # æ¨™æº–å·¥ä½œæµç¨‹æ¨¡æ¿ (å¾ 39 å€‹ GHX ç¯„ä¾‹å­¸ç¿’)
    STANDARD_WORKFLOWS = {
        "wasp": {
            "name": "WASP Aggregation",
            "description": "æ¨™æº– WASP èšé›†å·¥ä½œæµç¨‹ (å¾ 0_01_Basic_Aggregation.ghx å­¸ç¿’)",
            "stages": [
                {"stage": "å¹¾ä½•ç”Ÿæˆ", "components": ["Box", "Center Box", "Sphere", "Mesh"]},
                {"stage": "Meshè½‰æ›", "components": ["Mesh Brep"], "required": True, "reason": "WASP éœ€è¦ Mesh!"},
                {"stage": "é€£æ¥é»è¨­å®š", "components": ["Wasp_Connection From Direction", "Line SDL", "Area"]},
                {"stage": "Partå»ºç«‹", "components": ["Wasp_Basic Part"], "required": True},
                {"stage": "è¦å‰‡ç”Ÿæˆ", "components": ["Wasp_Rules Generator"], "required": True},
                {"stage": "èšé›†åŸ·è¡Œ", "components": ["Wasp_Stochastic Aggregation"], "required": True},
                {"stage": "è¼¸å‡º", "components": ["Wasp_Get Part Geometry", "Custom Preview"], "required": True},
            ],
            "key_connections": [
                {"from": "Wasp_Connection From Direction", "fromParam": "CONN", "to": "Wasp_Basic Part", "toParam": "CONN", "frequency": 33},
                {"from": "Wasp_Basic Part", "fromParam": "PART", "to": "Wasp_Rules Generator", "toParam": "PART", "frequency": 14},
                {"from": "Wasp_Rules Generator", "fromParam": "R", "to": "Wasp_Stochastic Aggregation", "toParam": "RULES", "frequency": 21},
                {"from": "Wasp_Basic Part", "fromParam": "PART", "to": "Wasp_Stochastic Aggregation", "toParam": "PART", "frequency": 11},
                {"from": "Wasp_Stochastic Aggregation", "fromParam": "PART_OUT", "to": "Wasp_Get Part Geometry", "toParam": "PART", "frequency": 11},
                {"from": "Wasp_Get Part Geometry", "fromParam": "GEO", "to": "Custom Preview", "toParam": "G", "frequency": 38},
                {"from": "Line SDL", "fromParam": "L", "to": "Wasp_Connection From Direction", "toParam": "UP", "frequency": 6},
            ]
        },
        "karamba": {
            "name": "Karamba Structural Analysis",
            "description": "æ¨™æº– Karamba çµæ§‹åˆ†ææµç¨‹",
            "stages": [
                {"stage": "å¹¾ä½•ç”Ÿæˆ", "components": ["Line", "Curve"]},
                {"stage": "Beamå®šç¾©", "components": ["LineToBeam"], "required": True},
                {"stage": "æ¨¡å‹çµ„è£", "components": ["Assemble"], "required": True},
                {"stage": "åˆ†æ", "components": ["Analyze"], "required": True},
                {"stage": "è¼¸å‡º", "components": ["ModelView", "BeamView"]},
            ]
        },
        "kangaroo": {
            "name": "Kangaroo Form Finding",
            "description": "æ¨™æº– Kangaroo æ‰¾å½¢æµç¨‹",
            "stages": [
                {"stage": "å¹¾ä½•è¼¸å…¥", "components": ["Mesh", "Points"]},
                {"stage": "Goalså®šç¾©", "components": ["Anchor", "Length", "SoapFilm"]},
                {"stage": "Solver", "components": ["Solver", "Zombie Solver"], "required": True},
                {"stage": "è¼¸å‡º", "components": ["Custom Preview"]},
            ]
        }
    }

    # ç³»çµ± prompt æ¨¡æ¿
    SYSTEM_PROMPT = """ä½ æ˜¯ Grasshopper åƒæ•¸åŒ–è¨­è¨ˆå°ˆå®¶ã€‚

ä½ çš„ä»»å‹™æ˜¯æ ¹æ“šç”¨æˆ¶éœ€æ±‚ç”Ÿæˆ Grasshopper çµ„ä»¶é…ç½®ã€‚

## æ ¸å¿ƒåŸå‰‡ï¼šåŸºæ–¼ç¯„ä¾‹å­¸ç¿’ï¼Œä¸è¦è‡ªå·±äº‚æƒ³ï¼

ä½ å¿…é ˆåƒè€ƒæä¾›çš„ã€Œå­¸ç¿’è³‡æ–™ã€å’Œã€Œæ¨™æº–å·¥ä½œæµç¨‹ã€ä¾†ç”Ÿæˆé…ç½®ï¼š
1. ä½¿ç”¨å­¸ç¿’è³‡æ–™ä¸­**é«˜é »ç‡**çš„é€£æ¥æ¨¡å¼ (frequency >= 10)
2. ç¢ºä¿å·¥ä½œæµç¨‹**å®Œæ•´**ï¼Œä¸è¦æ¼æ‰é—œéµéšæ®µ
3. çµ„ä»¶åç¨±å¿…é ˆèˆ‡å­¸ç¿’è³‡æ–™**å®Œå…¨ä¸€è‡´** (å¦‚ "Wasp_Basic Part" ä¸æ˜¯ "WASP Part")

## è¼¸å‡ºæ ¼å¼

ä½ å¿…é ˆè¼¸å‡º JSON æ ¼å¼çš„é…ç½®ï¼ŒåŒ…å«:
- components: çµ„ä»¶åˆ—è¡¨
- connections: é€£æ¥åˆ—è¡¨

æ¯å€‹çµ„ä»¶æ ¼å¼:
```json
{
  "id": "å”¯ä¸€ID",
  "type": "çµ„ä»¶é¡å‹ (å¿…é ˆèˆ‡å­¸ç¿’è³‡æ–™ä¸€è‡´)",
  "nickname": "çµ„ä»¶æš±ç¨±",
  "guid": "å¯é¸ï¼Œç•¶æœ‰è¡çªæ™‚ä½¿ç”¨ trusted GUID",
  "value": "åˆå§‹å€¼ (Slider/Panel ä½¿ç”¨)",
  "min": "æœ€å°å€¼ (Slider ä½¿ç”¨)",
  "max": "æœ€å¤§å€¼ (Slider ä½¿ç”¨)",
  "col": "åˆ—ä½ç½® (0-based)",
  "row": "è¡Œä½ç½® (0-based)"
}
```

æ¯å€‹é€£æ¥æ ¼å¼:
```json
{
  "from": "ä¾†æºçµ„ä»¶ID",
  "fromParam": "ä¾†æºåƒæ•¸å (å¿…é ˆèˆ‡å­¸ç¿’è³‡æ–™ä¸€è‡´)",
  "fromParamIndex": 0,
  "to": "ç›®æ¨™çµ„ä»¶ID",
  "toParam": "ç›®æ¨™åƒæ•¸å (å¿…é ˆèˆ‡å­¸ç¿’è³‡æ–™ä¸€è‡´)",
  "toParamIndex": 0
}
```

## é‡è¦è¦å‰‡

1. **å®Œæ•´æµç¨‹**: å¿…é ˆåŒ…å«å¾è¼¸å…¥åˆ°è¼¸å‡ºçš„å®Œæ•´å·¥ä½œæµç¨‹ï¼Œä¸èƒ½åªåšä¸€åŠ
2. **å­¸ç¿’è³‡æ–™å„ªå…ˆ**: ä½¿ç”¨å­¸ç¿’è³‡æ–™ä¸­å‡ºç¾éçš„é€£æ¥æ¨¡å¼
3. **Slider è¨­å®šé †åº**: å…ˆè¨­ min/maxï¼Œå†è¨­ value (é¿å… clamping)
4. **GUID è¡çªçµ„ä»¶**: Rotate, Pipe, Series ç­‰éœ€ä½¿ç”¨ trusted GUID
5. **Panel ä¸èƒ½ä½œæ•¸å€¼è¼¸å…¥**: æ”¹ç”¨ Number Slider
6. **WASP éœ€è¦ Mesh**: Wasp_Basic Part çš„ GEO å¿…é ˆæ¥ Meshï¼Œä¸èƒ½æ¥ Brep

## å›æ‡‰æ ¼å¼

åªè¼¸å‡º JSONï¼Œä¸è¦åŒ…å«å…¶ä»–èªªæ˜æ–‡å­—:

```json
{
  "components": [...],
  "connections": [],
  "_meta": {
    "description": "é…ç½®èªªæ˜",
    "workflow_stages": ["éšæ®µ1", "éšæ®µ2", ...],
    "generated_at": "timestamp"
  }
}
```
"""

    def __init__(
        self,
        config_dir: str = "config",
        claude_client: Optional[Any] = None,
        model: str = "claude-sonnet-4-20250514"
    ):
        """
        åˆå§‹åŒ–è¨ˆç•«ç”Ÿæˆå™¨

        Args:
            config_dir: é…ç½®ç›®éŒ„è·¯å¾‘
            claude_client: Claude API å®¢æˆ¶ç«¯ (å¯é¸)
            model: ä½¿ç”¨çš„æ¨¡å‹
        """
        self.config_dir = Path(config_dir)
        self.claude_client = claude_client
        self.model = model

        # è¼‰å…¥çŸ¥è­˜åº«
        self._trusted_guids = self._load_json("trusted_guids.json")
        self._connection_patterns = self._load_json("connection_patterns.json")
        self._mcp_commands = self._load_json("mcp_commands.json")

        # è¼‰å…¥å­¸ç¿’è³‡æ–™ (å¾ GHX åˆ†æå¾—ä¾†)
        self._connection_triplets = self._load_json("connection_triplets.json")
        self._component_params = self._load_json("wasp_component_params.json")

    def _load_json(self, filename: str) -> Dict:
        """è¼‰å…¥ JSON é…ç½®æ–‡ä»¶"""
        path = self.config_dir / filename
        if path.exists():
            try:
                with open(path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception:
                pass
        return {}

    def generate(
        self,
        user_input: str,
        partial_knowledge: Dict,
        context: Optional[Dict] = None,
        auto_complete: bool = True
    ) -> ExecutionPlan:
        """
        ä¸€æ¬¡ Claude èª¿ç”¨ï¼Œç”Ÿæˆå®Œæ•´è¨ˆç•«

        Args:
            user_input: ç”¨æˆ¶è«‹æ±‚
            partial_knowledge: éƒ¨åˆ†åŒ¹é…çš„çŸ¥è­˜ (from IntegrationBridge.search)
            context: é¡å¤–ä¸Šä¸‹æ–‡
            auto_complete: æ˜¯å¦è‡ªå‹•è£œå…¨ç¼ºå¤±çš„å·¥ä½œæµç¨‹éšæ®µ

        Returns:
            ExecutionPlan
        """
        context = context or {}

        # æª¢æ¸¬å·¥ä½œæµç¨‹é¡å‹
        workflow_type = self.detect_workflow_type(user_input)

        # å¦‚æœæœ‰å°æ‡‰çš„æ¨™æº–å·¥ä½œæµç¨‹ï¼Œå°‡æ¨¡æ¿æ³¨å…¥ context
        if workflow_type:
            template = self.get_workflow_template(workflow_type)
            if template:
                context["standard_workflow"] = template

        # å»ºç«‹ prompt
        prompt = self._build_prompt(user_input, partial_knowledge, context)

        # å¦‚æœæ²’æœ‰ Claude clientï¼Œè¿”å›éŒ¯èª¤
        if self.claude_client is None:
            return ExecutionPlan(
                success=False,
                errors=["No Claude client configured"],
                generation_context={
                    "prompt_length": len(prompt),
                    "workflow_type": workflow_type,
                    "knowledge_injected": {
                        "triplets": len(partial_knowledge.get("triplets", [])),
                        "patterns": len(partial_knowledge.get("patterns", [])),
                    }
                }
            )

        # èª¿ç”¨ Claude
        try:
            response = self._call_claude(prompt)
            plan = self._parse_response(response)

            plan.generation_context = {
                "model": self.model,
                "prompt_length": len(prompt),
                "workflow_type": workflow_type,
                "knowledge_injected": {
                    "triplets": len(partial_knowledge.get("triplets", [])),
                    "patterns": len(partial_knowledge.get("patterns", [])),
                }
            }

            # é©—è­‰å·¥ä½œæµç¨‹å®Œæ•´æ€§
            if workflow_type and plan.success:
                validation = self.validate_workflow_completeness(plan, workflow_type)
                plan.generation_context["workflow_validation"] = validation

                # å¦‚æœä¸å®Œæ•´ä¸”å•Ÿç”¨è‡ªå‹•è£œå…¨
                if not validation["complete"] and auto_complete:
                    plan = self.auto_complete_workflow(plan, workflow_type)
                    plan.warnings.extend(validation["suggestions"])
                elif not validation["complete"]:
                    # ä¸è‡ªå‹•è£œå…¨ï¼Œä½†æ·»åŠ è­¦å‘Š
                    plan.warnings.extend(validation["suggestions"])

            return plan

        except Exception as e:
            return ExecutionPlan(
                success=False,
                errors=[f"Claude API error: {str(e)}"],
                generation_context={
                    "prompt_length": len(prompt),
                    "workflow_type": workflow_type
                }
            )

    def generate_with_mermaid(
        self,
        user_input: str,
        partial_knowledge: Dict,
        wip_dir: Path = Path("GH_WIP"),
        context: Optional[Dict] = None
    ) -> Tuple[ExecutionPlan, Path]:
        """
        ç”ŸæˆåŸ·è¡Œè¨ˆç•« + Mermaid å¯è¦–åŒ–

        Args:
            user_input: ç”¨æˆ¶è«‹æ±‚
            partial_knowledge: éƒ¨åˆ†åŒ¹é…çš„çŸ¥è­˜
            wip_dir: å·¥ä½œç›®éŒ„è·¯å¾‘
            context: é¡å¤–ä¸Šä¸‹æ–‡

        Returns:
            (plan, mermaid_path)
        """
        # ç¢ºä¿ç›®éŒ„å­˜åœ¨
        wip_dir = Path(wip_dir)
        wip_dir.mkdir(exist_ok=True)

        # 1. ç”Ÿæˆè¨ˆç•«
        plan = self.generate(user_input, partial_knowledge, context)

        # 2. ç”Ÿæˆ Mermaid æµç¨‹åœ–
        mermaid_content = self._plan_to_mermaid(plan, user_input)
        mermaid_path = wip_dir / "component_info.mmd"
        mermaid_path.write_text(mermaid_content, encoding="utf-8")

        # 3. æ›´æ–° generation_context
        plan.generation_context["mermaid_path"] = str(mermaid_path)
        plan.generation_context["description"] = user_input

        return plan, mermaid_path

    def _plan_to_mermaid(self, plan: ExecutionPlan, description: str = "") -> str:
        """
        å°‡è¨ˆç•«è½‰æ›ç‚º Mermaid flowchart

        Args:
            plan: åŸ·è¡Œè¨ˆç•«
            description: è¨ˆç•«æè¿°

        Returns:
            Mermaid flowchart å­—ç¬¦ä¸²
        """
        lines = [
            "flowchart LR",
            f"    %% è‡ªå‹•ç”Ÿæˆ - {datetime.now().strftime('%Y-%m-%d %H:%M')}",
            f"    %% æè¿°: {description}",
            "    %% è«‹åœ¨ VSCode ä¸­é è¦½ä¸¦ç¢ºèª",
            "",
        ]

        if not plan.success or not plan.components:
            lines.append("    %% è¨ˆç•«ç”Ÿæˆå¤±æ•—æˆ–ç„¡çµ„ä»¶")
            if plan.errors:
                for err in plan.errors[:3]:
                    lines.append(f"    %% Error: {err}")
            return "\n".join(lines)

        # å°‡çµ„ä»¶æŒ‰é¡å‹åˆ†çµ„
        groups = self._group_components(plan.components)

        # çµ„ä»¶å­åœ–
        for group_name, components in groups.items():
            # æ¸…ç† group_nameï¼Œç§»é™¤ç‰¹æ®Šå­—ç¬¦
            safe_group_name = group_name.replace(" ", "_").replace("-", "_")
            lines.append(f'    subgraph {safe_group_name}["{group_name}"]')
            for comp in components:
                comp_id = comp.get("id", "unknown")
                comp_type = comp.get("type", "Unknown")
                nickname = comp.get("nickname", comp_id)
                # è™•ç† Slider çš„é¡å¤–ä¿¡æ¯
                if "Slider" in comp_type or "slider" in comp_type.lower():
                    value = comp.get("value", "")
                    min_val = comp.get("min", "")
                    max_val = comp.get("max", "")
                    if value:
                        lines.append(
                            f'        {comp_id}["{comp_type}<br/>'
                            f'nickname: {nickname}<br/>'
                            f'value: {value} ({min_val}-{max_val})"]'
                        )
                    else:
                        lines.append(
                            f'        {comp_id}["{comp_type}<br/>'
                            f'nickname: {nickname}"]'
                        )
                else:
                    lines.append(
                        f'        {comp_id}["{comp_type}<br/>'
                        f'nickname: {nickname}"]'
                    )
            lines.append("    end")
            lines.append("")

        # é€£æ¥ (å«å­¸ç¿’è³‡æ–™é©—è­‰)
        if plan.connections:
            lines.append("    %% é€£æ¥")

            # å»ºç«‹çµ„ä»¶ ID åˆ°é¡å‹çš„æ˜ å°„
            id_to_type = {c.get("id", ""): c.get("type", "") for c in plan.components}

            for conn in plan.connections:
                from_id = conn.get("from", "")
                to_id = conn.get("to", "")
                from_param = conn.get("fromParam", conn.get("from_param", ""))
                to_param = conn.get("toParam", conn.get("to_param", ""))

                # é©—è­‰é€£æ¥æ˜¯å¦åœ¨å­¸ç¿’è³‡æ–™ä¸­
                from_type = id_to_type.get(from_id, "")
                to_type = id_to_type.get(to_id, "")

                # å˜—è©¦ç²å–æ¨™æº–çµ„ä»¶åç¨±
                canonical_from = self.get_canonical_component_name(from_type) or from_type
                canonical_to = self.get_canonical_component_name(to_type) or to_type

                validation = self.validate_connection(
                    canonical_from, from_param, canonical_to, to_param
                )

                # æ ¹æ“šé©—è­‰çµæœèª¿æ•´é€£æ¥æ¨™ç±¤
                confidence_icon = ""
                if validation["valid"]:
                    freq = validation["frequency"]
                    if freq >= 10:
                        confidence_icon = "âœ…"  # é«˜é »é€£æ¥
                    elif freq >= 5:
                        confidence_icon = "ğŸŸ¡"  # ä¸­é »é€£æ¥
                    else:
                        confidence_icon = "ğŸ”µ"  # ä½é »ä½†æœ‰è¨˜éŒ„

                if from_id and to_id:
                    if from_param or to_param:
                        label = f"{from_param} â†’ {to_param}"
                        if confidence_icon:
                            label = f"{confidence_icon} {label}"
                        lines.append(f'    {from_id} -->|"{label}"| {to_id}')
                    else:
                        lines.append(f'    {from_id} --> {to_id}')

        return "\n".join(lines)

    def _group_components(self, components: List[Dict]) -> Dict[str, List[Dict]]:
        """
        æŒ‰é¡å‹åˆ†çµ„çµ„ä»¶

        åˆ†çµ„è¦å‰‡ (æŒ‰ç…§ WASP å·¥ä½œæµç¨‹éšæ®µ):
        - Slider/Number â†’ "åƒæ•¸ Parameters"
        - Box/Brep å¹¾ä½• â†’ "å¹¾ä½•ç”Ÿæˆ Geometry"
        - Mesh Brep â†’ "Meshè½‰æ› Mesh_Convert"
        - Wasp_Connection â†’ "é€£æ¥é»è¨­å®š Connection"
        - Wasp_Part â†’ "Partå»ºç«‹ Part_Build"
        - Wasp_Rules â†’ "è¦å‰‡ç”Ÿæˆ Rules"
        - Wasp_Aggregation â†’ "èšé›†åŸ·è¡Œ Aggregation"
        - Preview/Get Geometry â†’ "è¼¸å‡º Output"
        """
        groups: Dict[str, List[Dict]] = {}

        for comp in components:
            comp_type = comp.get("type", "").lower()
            comp_type_original = comp.get("type", "")

            # WASP ç‰¹å®šåˆ†çµ„ (æŒ‰å·¥ä½œæµç¨‹éšæ®µ)
            if "wasp_connection" in comp_type:
                group = "é€£æ¥é»è¨­å®š Connection"
            elif "wasp_basic part" in comp_type or "wasp_part" in comp_type:
                group = "Partå»ºç«‹ Part_Build"
            elif "wasp_rules" in comp_type:
                group = "è¦å‰‡ç”Ÿæˆ Rules"
            elif "wasp_aggregation" in comp_type or "wasp_stochastic" in comp_type or "wasp_field" in comp_type:
                group = "èšé›†åŸ·è¡Œ Aggregation"
            elif "wasp_get" in comp_type:
                group = "è¼¸å‡º Output"
            # Karamba åˆ†çµ„
            elif "karamba" in comp_type or "linetobeam" in comp_type or "assemble" in comp_type or "analyze" in comp_type:
                group = "çµæ§‹åˆ†æ Structural"
            # Kangaroo åˆ†çµ„
            elif "kangaroo" in comp_type or "solver" in comp_type or "anchor" in comp_type or "goal" in comp_type:
                group = "æ‰¾å½¢ FormFinding"
            # é€šç”¨åˆ†çµ„
            elif any(kw in comp_type for kw in ["slider", "number", "panel", "param"]):
                group = "åƒæ•¸ Parameters"
            elif any(kw in comp_type for kw in ["mesh brep", "mesh"]) and "wasp" not in comp_type:
                group = "Meshè½‰æ› Mesh_Convert"
            elif any(kw in comp_type for kw in ["box", "center box", "sphere", "cylinder"]):
                group = "å¹¾ä½•ç”Ÿæˆ Geometry"
            elif any(kw in comp_type for kw in ["point", "vector", "plane", "xyz"]):
                group = "å¹¾ä½•åŸºå…ƒ Primitives"
            elif any(kw in comp_type for kw in ["line", "circle", "curve", "arc", "polyline", "line sdl"]):
                group = "æ›²ç·š Curves"
            elif any(kw in comp_type for kw in ["surface", "brep", "extrude", "loft"]):
                group = "æ›²é¢ Surfaces"
            elif any(kw in comp_type for kw in ["area", "face", "deconstruct"]):
                group = "å¹¾ä½•åˆ†æ Analysis"
            elif any(kw in comp_type for kw in ["division", "series", "multiply", "add", "subtract", "math", "sin", "cos", "radian"]):
                group = "è¨ˆç®—é‚è¼¯ Calculations"
            elif any(kw in comp_type for kw in ["rotate", "move", "scale", "transform", "orient"]):
                group = "è®Šæ› Transforms"
            elif any(kw in comp_type for kw in ["preview", "custom preview"]):
                group = "è¼¸å‡º Output"
            else:
                group = "è™•ç† Processing"

            if group not in groups:
                groups[group] = []
            groups[group].append(comp)

        # æŒ‰å·¥ä½œæµç¨‹é †åºæ’åºçµ„åˆ¥
        workflow_order = [
            "åƒæ•¸ Parameters",
            "å¹¾ä½•ç”Ÿæˆ Geometry",
            "å¹¾ä½•åŸºå…ƒ Primitives",
            "æ›²ç·š Curves",
            "æ›²é¢ Surfaces",
            "Meshè½‰æ› Mesh_Convert",
            "å¹¾ä½•åˆ†æ Analysis",
            "é€£æ¥é»è¨­å®š Connection",
            "Partå»ºç«‹ Part_Build",
            "è¦å‰‡ç”Ÿæˆ Rules",
            "èšé›†åŸ·è¡Œ Aggregation",
            "è¨ˆç®—é‚è¼¯ Calculations",
            "è®Šæ› Transforms",
            "çµæ§‹åˆ†æ Structural",
            "æ‰¾å½¢ FormFinding",
            "è™•ç† Processing",
            "è¼¸å‡º Output",
        ]

        ordered_groups: Dict[str, List[Dict]] = {}
        for group_name in workflow_order:
            if group_name in groups:
                ordered_groups[group_name] = groups[group_name]

        # æ·»åŠ ä»»ä½•æœªåœ¨é †åºä¸­çš„çµ„åˆ¥
        for group_name, comps in groups.items():
            if group_name not in ordered_groups:
                ordered_groups[group_name] = comps

        return ordered_groups

    def _build_prompt(
        self,
        user_input: str,
        partial_knowledge: Dict,
        context: Dict
    ) -> str:
        """
        å»ºç«‹æ³¨å…¥çŸ¥è­˜çš„ prompt

        çŸ¥è­˜æ³¨å…¥:
        1. ç›¸é—œé€£æ¥ä¸‰å…ƒçµ„ (çµ±è¨ˆé »ç‡) - å¾ GHX å­¸ç¿’
        2. çµ„ä»¶åƒæ•¸è³‡è¨Š - å¾ GHX å­¸ç¿’
        3. åŒ¹é…çš„é€£æ¥æ¨¡å¼
        4. è¡çªçµ„ä»¶çš„ trusted GUID
        """
        sections = []

        # ç”¨æˆ¶è«‹æ±‚
        sections.append(f"## ç”¨æˆ¶è«‹æ±‚\n\n{user_input}")

        # æ³¨å…¥é€£æ¥ä¸‰å…ƒçµ„ (å„ªå…ˆä½¿ç”¨ partial_knowledgeï¼Œå¦å‰‡å¾æœ¬åœ°å­¸ç¿’è³‡æ–™æŸ¥è©¢)
        triplets = partial_knowledge.get("triplets", [])
        if not triplets:
            # å¾ç”¨æˆ¶è¼¸å…¥æå–é—œéµå­—ä¸¦æŸ¥è©¢å­¸ç¿’è³‡æ–™
            keywords = self._extract_keywords_from_input(user_input)
            triplets = self.get_learned_triplets(keywords, limit=15)

        if triplets:
            triplet_text = self._format_triplets(triplets[:15])
            sections.append(
                f"## å­¸ç¿’åˆ°çš„é€£æ¥æ¨¡å¼ (å¾ {self._connection_triplets.get('metadata', {}).get('analyzed_files', '?')} å€‹ GHX æ–‡ä»¶)\n\n"
                f"{triplet_text}"
            )

        # æ³¨å…¥çµ„ä»¶åƒæ•¸è³‡è¨Š (æ–°å¢ï¼šå¾å­¸ç¿’è³‡æ–™)
        relevant_components = self._get_relevant_component_params(user_input)
        if relevant_components:
            params_text = self._format_component_params(relevant_components)
            sections.append(f"## çµ„ä»¶åƒæ•¸åƒè€ƒ (å¾ GHX å­¸ç¿’)\n\n{params_text}")

        # æ³¨å…¥é€£æ¥æ¨¡å¼
        patterns = partial_knowledge.get("patterns", [])
        if patterns:
            pattern_text = self._format_patterns(patterns[:5])
            sections.append(f"## é å®šç¾©é€£æ¥æ¨¡å¼\n\n{pattern_text}")

        # æ³¨å…¥ trusted GUIDs
        guid_text = self._format_trusted_guids()
        if guid_text:
            sections.append(f"## è¡çªçµ„ä»¶ GUID\n\n{guid_text}")

        # æ³¨å…¥æ¨™æº–å·¥ä½œæµç¨‹æ¨¡æ¿ (å¦‚æœæœ‰)
        standard_workflow = context.pop("standard_workflow", None)
        if standard_workflow:
            workflow_text = self._format_standard_workflow(standard_workflow)
            sections.append(f"## æ¨™æº–å·¥ä½œæµç¨‹ (å¿…é ˆéµå¾ªï¼)\n\n{workflow_text}")

        # æ³¨å…¥é¡å¤–ä¸Šä¸‹æ–‡
        if context:
            context_text = json.dumps(context, indent=2, ensure_ascii=False)
            sections.append(f"## é¡å¤–ä¸Šä¸‹æ–‡\n\n```json\n{context_text}\n```")

        return "\n\n---\n\n".join(sections)

    def _format_standard_workflow(self, workflow: Dict) -> str:
        """æ ¼å¼åŒ–æ¨™æº–å·¥ä½œæµç¨‹æ¨¡æ¿"""
        lines = [
            f"### {workflow.get('name', 'Unknown Workflow')}",
            "",
            f"{workflow.get('description', '')}",
            "",
            "**å¿…è¦éšæ®µ (ä¸å¯çœç•¥ï¼):**",
            ""
        ]

        for stage_info in workflow.get("stages", []):
            stage_name = stage_info.get("stage", "")
            components = stage_info.get("components", [])
            required = stage_info.get("required", False)
            reason = stage_info.get("reason", "")

            marker = "âš ï¸ **å¿…è¦**" if required else ""
            lines.append(f"- **{stage_name}**: {', '.join(components)} {marker}")
            if reason:
                lines.append(f"  - åŸå› : {reason}")

        # æ·»åŠ é—œéµé€£æ¥
        key_connections = workflow.get("key_connections", [])
        if key_connections:
            lines.extend([
                "",
                "**é—œéµé€£æ¥æ¨¡å¼ (å¾ GHX ç¯„ä¾‹å­¸ç¿’):**",
                "",
                "| ä¾†æº | åƒæ•¸ | ç›®æ¨™ | åƒæ•¸ | é »ç‡ |",
                "|------|------|------|------|------|"
            ])
            for conn in key_connections:
                lines.append(
                    f"| {conn['from']} | {conn['fromParam']} | "
                    f"{conn['to']} | {conn['toParam']} | {conn['frequency']}x |"
                )

        return "\n".join(lines)

    def _extract_keywords_from_input(self, text: str) -> List[str]:
        """å¾ç”¨æˆ¶è¼¸å…¥æå–é—œéµå­—"""
        domain_keywords = {
            'wasp': ['wasp', 'èšé›†', 'aggregation', 'part', 'é›¶ä»¶'],
            'karamba': ['karamba', 'çµæ§‹', 'structural', 'beam', 'æ¢'],
            'kangaroo': ['kangaroo', 'æ‰¾å½¢', 'tensile', 'membrane', 'å¼µåŠ›'],
            'ladybug': ['ladybug', 'æ—¥ç…§', 'solar', 'shadow', 'é™°å½±'],
            'mesh': ['mesh', 'ç¶²æ ¼', 'subdivision', 'ç´°åˆ†'],
        }

        text_lower = text.lower()
        extracted = []

        for category, kws in domain_keywords.items():
            for kw in kws:
                if kw in text_lower:
                    extracted.append(category)
                    break

        return extracted if extracted else ['wasp']  # é è¨­ wasp

    def _get_relevant_component_params(self, user_input: str) -> Dict[str, Dict]:
        """æ ¹æ“šç”¨æˆ¶è¼¸å…¥ç²å–ç›¸é—œçš„çµ„ä»¶åƒæ•¸"""
        components = self._component_params.get("components", {})
        if not components:
            return {}

        user_lower = user_input.lower()
        relevant = {}

        # é—œéµå­—åˆ°çµ„ä»¶çš„æ˜ å°„
        keyword_to_components = {
            'wasp': ['Wasp_Basic Part', 'Wasp_Connection From Direction', 'Wasp_Rules Generator', 'Wasp_Stochastic Aggregation'],
            'part': ['Wasp_Basic Part', 'Wasp_Connection From Direction'],
            'connection': ['Wasp_Connection From Direction'],
            'rule': ['Wasp_Rules Generator'],
            'aggregation': ['Wasp_Stochastic Aggregation', 'Wasp_Field-driven Aggregation'],
        }

        for kw, comp_names in keyword_to_components.items():
            if kw in user_lower:
                for name in comp_names:
                    if name in components and name not in relevant:
                        relevant[name] = components[name]

        return relevant

    def _format_component_params(self, components: Dict[str, Dict]) -> str:
        """æ ¼å¼åŒ–çµ„ä»¶åƒæ•¸è³‡è¨Š"""
        lines = []

        for name, info in components.items():
            lines.append(f"### {name}")

            inputs = info.get("inputs", [])
            if inputs:
                lines.append("\n**è¼¸å…¥åƒæ•¸:**")
                for inp in inputs:
                    nick = inp.get("nickname", "")
                    desc = inp.get("description", "")[:80]
                    lines.append(f"- `{nick}`: {desc}")

            outputs = info.get("outputs", [])
            if outputs:
                lines.append("\n**è¼¸å‡ºåƒæ•¸:**")
                for out in outputs:
                    nick = out.get("nickname", "")
                    desc = out.get("description", "")[:80]
                    lines.append(f"- `{nick}`: {desc}")

            lines.append("")

        return "\n".join(lines)

    def _format_triplets(self, triplets: List[Dict]) -> str:
        """æ ¼å¼åŒ–é€£æ¥ä¸‰å…ƒçµ„"""
        lines = ["| ä¾†æº | ä¾†æºåƒæ•¸ | ç›®æ¨™ | ç›®æ¨™åƒæ•¸ | é »ç‡ |",
                 "|------|----------|------|----------|------|"]

        for t in triplets:
            lines.append(
                f"| {t.get('source_component', '')} | "
                f"{t.get('source_param', '')} | "
                f"{t.get('target_component', '')} | "
                f"{t.get('target_param', '')} | "
                f"{t.get('frequency', 0)} |"
            )

        return "\n".join(lines)

    def _format_patterns(self, patterns: List[Dict]) -> str:
        """æ ¼å¼åŒ–é€£æ¥æ¨¡å¼"""
        lines = []

        for p in patterns:
            name = p.get("name", "Unknown")
            desc = p.get("description", "")
            wiring = p.get("wiring", [])

            lines.append(f"### {name}")
            if desc:
                lines.append(f"\n{desc}")
            if wiring:
                lines.append("\né€£æ¥:")
                for w in wiring[:5]:  # é™åˆ¶æ•¸é‡
                    lines.append(f"- {w.get('from', '')} â†’ {w.get('to', '')}")
            lines.append("")

        return "\n".join(lines)

    def _format_trusted_guids(self) -> str:
        """æ ¼å¼åŒ– trusted GUIDs"""
        components = self._trusted_guids.get("components", {})
        conflict_components = ["Rotate", "Pipe", "Series", "Line", "Point", "Circle"]

        lines = ["| çµ„ä»¶ | GUID | è¡çªèªªæ˜ |",
                 "|------|------|----------|"]

        for name in conflict_components:
            info = components.get(name, {})
            if info:
                guid = info.get("guid", "")[:36]  # é™åˆ¶é•·åº¦
                conflicts = ", ".join(info.get("known_conflicts", []))
                lines.append(f"| {name} | `{guid}...` | {conflicts} |")

        return "\n".join(lines) if len(lines) > 2 else ""

    # =========================================================================
    # å­¸ç¿’è³‡æ–™æŸ¥è©¢ (å¾ GHX åˆ†æå¾—ä¾†)
    # =========================================================================

    def get_learned_triplets(self, keywords: List[str], limit: int = 10) -> List[Dict]:
        """
        æ ¹æ“šé—œéµå­—æŸ¥è©¢å­¸ç¿’åˆ°çš„é€£æ¥ä¸‰å…ƒçµ„

        Args:
            keywords: é—œéµå­—åˆ—è¡¨ (å¦‚ ["wasp", "part"])
            limit: è¿”å›æ•¸é‡ä¸Šé™

        Returns:
            åŒ¹é…çš„ä¸‰å…ƒçµ„åˆ—è¡¨ï¼ŒæŒ‰é »ç‡æ’åº
        """
        triplets = self._connection_triplets.get("triplets", [])
        if not triplets:
            return []

        keywords_lower = {k.lower() for k in keywords}
        matched = []

        for t in triplets:
            source = t.get("source_component", "").lower()
            target = t.get("target_component", "").lower()

            if any(kw in source or kw in target for kw in keywords_lower):
                matched.append(t)

        # æŒ‰é »ç‡æ’åº
        matched.sort(key=lambda x: x.get("frequency", 0), reverse=True)
        return matched[:limit]

    def get_component_params(self, component_name: str) -> Optional[Dict]:
        """
        ç²å–çµ„ä»¶çš„åƒæ•¸è³‡è¨Š (å¾ wasp_component_params.json)

        Args:
            component_name: çµ„ä»¶åç¨± (å¦‚ "Wasp_Basic Part")

        Returns:
            çµ„ä»¶åƒæ•¸è³‡è¨Šï¼ŒåŒ…å« inputs å’Œ outputs
        """
        components = self._component_params.get("components", {})
        return components.get(component_name)

    def validate_connection(
        self,
        source_component: str,
        source_param: str,
        target_component: str,
        target_param: str
    ) -> Dict:
        """
        é©—è­‰é€£æ¥æ˜¯å¦åœ¨å­¸ç¿’è³‡æ–™ä¸­æœ‰è¨˜éŒ„

        Returns:
            {
                "valid": bool,
                "frequency": int,      # 0 è¡¨ç¤ºæœªè¦‹é
                "confidence": float,   # 0.0-1.0
                "examples": List[str]  # å‡ºç¾åœ¨å“ªäº› GHX æ–‡ä»¶
            }
        """
        triplets = self._connection_triplets.get("triplets", [])

        for t in triplets:
            if (t.get("source_component", "") == source_component and
                t.get("source_param", "") == source_param and
                t.get("target_component", "") == target_component and
                t.get("target_param", "") == target_param):

                freq = t.get("frequency", 0)
                confidence = min(1.0, freq / 10.0)  # 10+ æ¬¡è¦–ç‚ºé«˜ç½®ä¿¡

                return {
                    "valid": True,
                    "frequency": freq,
                    "confidence": confidence,
                    "examples": t.get("examples", [])[:5]
                }

        return {
            "valid": False,
            "frequency": 0,
            "confidence": 0.0,
            "examples": []
        }

    def get_canonical_component_name(self, nickname: str) -> Optional[str]:
        """
        å¾æš±ç¨±ç²å–æ¨™æº–çµ„ä»¶åç¨±

        ä¾‹å¦‚: "WASP Part" -> "Wasp_Basic Part"
        """
        components = self._component_params.get("components", {})

        # ç›´æ¥åŒ¹é…
        if nickname in components:
            return nickname

        # æ¨¡ç³ŠåŒ¹é…
        nickname_lower = nickname.lower().replace(" ", "_").replace("-", "_")
        for name in components:
            name_normalized = name.lower().replace(" ", "_")
            if nickname_lower in name_normalized or name_normalized in nickname_lower:
                return name

        return None

    # =========================================================================
    # å·¥ä½œæµç¨‹å®Œæ•´æ€§é©—è­‰ (é˜²æ­¢æ¼æ‰é—œéµéšæ®µ)
    # =========================================================================

    def detect_workflow_type(self, user_input: str) -> Optional[str]:
        """
        æ ¹æ“šç”¨æˆ¶è¼¸å…¥æª¢æ¸¬å·¥ä½œæµç¨‹é¡å‹

        Returns:
            å·¥ä½œæµç¨‹é¡å‹ ("wasp", "karamba", "kangaroo") æˆ– None

        Note:
            æª¢æ¸¬é †åºå¾ˆé‡è¦ï¼æ›´ç‰¹å®šçš„é—œéµå­—æ‡‰è©²å…ˆæª¢æ¸¬ã€‚
            ä¾‹å¦‚ "å¼µåŠ›è†œçµæ§‹" æ‡‰è©²å„ªå…ˆåŒ¹é… kangaroo è€Œé karambaã€‚
        """
        user_lower = user_input.lower()

        # æŒ‰å„ªå…ˆé †åºæ’åˆ—çš„é—œéµå­— (æ›´ç‰¹å®šçš„å…ˆæª¢æ¸¬)
        # ä¾‹å¦‚: kangaroo çš„ "å¼µåŠ›" æ¯” karamba çš„ "çµæ§‹" æ›´ç‰¹å®š
        workflow_keywords = [
            # Kangaroo å…ˆæª¢æ¸¬ (å› ç‚º "å¼µåŠ›è†œçµæ§‹" åŒ…å« "çµæ§‹")
            ("kangaroo", ["kangaroo", "æ‰¾å½¢", "tensile", "membrane", "å¼µåŠ›", "physics", "è¢‹é¼ "]),
            # WASP æ¬¡ä¹‹
            ("wasp", ["wasp", "èšé›†", "aggregation", "part", "é›¶ä»¶", "assembly"]),
            # Karamba æœ€å¾Œ (å› ç‚º "çµæ§‹" å¤ªé€šç”¨)
            ("karamba", ["karamba", "çµæ§‹åˆ†æ", "structural", "beam", "æ¢", "åŠ›å­¸", "æ¡¿ä»¶"]),
        ]

        for workflow_type, keywords in workflow_keywords:
            if any(kw in user_lower for kw in keywords):
                return workflow_type

        return None

    def get_workflow_template(self, workflow_type: str) -> Optional[Dict]:
        """
        ç²å–æ¨™æº–å·¥ä½œæµç¨‹æ¨¡æ¿

        Args:
            workflow_type: å·¥ä½œæµç¨‹é¡å‹

        Returns:
            å·¥ä½œæµç¨‹æ¨¡æ¿å­—å…¸
        """
        return self.STANDARD_WORKFLOWS.get(workflow_type)

    def validate_workflow_completeness(
        self,
        plan: ExecutionPlan,
        workflow_type: str
    ) -> Dict[str, Any]:
        """
        é©—è­‰è¨ˆç•«æ˜¯å¦åŒ…å«å·¥ä½œæµç¨‹çš„æ‰€æœ‰å¿…è¦éšæ®µ

        é€™æ˜¯é˜²æ­¢æ¼æ‰é—œéµçµ„ä»¶çš„æ ¸å¿ƒæ–¹æ³•ï¼
        ä¾‹å¦‚: WASP å·¥ä½œæµç¨‹å¿…é ˆæœ‰ Aggregation â†’ Get Geometry â†’ Preview

        Args:
            plan: ç”Ÿæˆçš„åŸ·è¡Œè¨ˆç•«
            workflow_type: å·¥ä½œæµç¨‹é¡å‹

        Returns:
            {
                "complete": bool,
                "missing_stages": List[str],
                "missing_components": List[str],
                "missing_connections": List[Dict],
                "warnings": List[str],
                "suggestions": List[str]
            }
        """
        template = self.STANDARD_WORKFLOWS.get(workflow_type)
        if not template:
            return {
                "complete": True,  # æ²’æœ‰æ¨¡æ¿å°±ä¸é©—è­‰
                "missing_stages": [],
                "missing_components": [],
                "missing_connections": [],
                "warnings": [f"No template found for workflow type: {workflow_type}"],
                "suggestions": []
            }

        # ç²å–è¨ˆç•«ä¸­çš„çµ„ä»¶é¡å‹
        plan_component_types = set()
        for comp in plan.components:
            comp_type = comp.get("type", "")
            plan_component_types.add(comp_type)
            # ä¹ŸåŠ å…¥æ¨™æº–åŒ–åç¨±
            canonical = self.get_canonical_component_name(comp_type)
            if canonical:
                plan_component_types.add(canonical)

        # æª¢æŸ¥å¿…è¦éšæ®µ
        missing_stages = []
        missing_components = []

        for stage_info in template.get("stages", []):
            stage_name = stage_info.get("stage", "")
            required = stage_info.get("required", False)
            stage_components = stage_info.get("components", [])

            # æª¢æŸ¥éšæ®µä¸­æ˜¯å¦æœ‰ä»»ä½•çµ„ä»¶å­˜åœ¨
            stage_has_component = any(
                comp in plan_component_types or
                self.get_canonical_component_name(comp) in plan_component_types
                for comp in stage_components
            )

            if required and not stage_has_component:
                missing_stages.append(stage_name)
                reason = stage_info.get("reason", "")
                if reason:
                    missing_components.append(f"{stage_components[0]} ({reason})")
                else:
                    missing_components.append(stage_components[0])

        # æª¢æŸ¥é—œéµé€£æ¥
        missing_connections = []
        plan_connections_set = set()

        for conn in plan.connections:
            key = (
                conn.get("from", ""),
                conn.get("fromParam", conn.get("from_param", "")),
                conn.get("to", ""),
                conn.get("toParam", conn.get("to_param", ""))
            )
            plan_connections_set.add(key)

        # å»ºç«‹ ID åˆ° Type çš„æ˜ å°„
        id_to_type = {c.get("id", ""): c.get("type", "") for c in plan.components}

        for key_conn in template.get("key_connections", []):
            from_type = key_conn.get("from", "")
            from_param = key_conn.get("fromParam", "")
            to_type = key_conn.get("to", "")
            to_param = key_conn.get("toParam", "")
            freq = key_conn.get("frequency", 0)

            # æª¢æŸ¥æ˜¯å¦æœ‰é¡ä¼¼çš„é€£æ¥
            has_connection = False
            for plan_conn in plan.connections:
                plan_from_id = plan_conn.get("from", "")
                plan_to_id = plan_conn.get("to", "")
                plan_from_type = id_to_type.get(plan_from_id, "")
                plan_to_type = id_to_type.get(plan_to_id, "")

                # æ¨™æº–åŒ–çµ„ä»¶åç¨±
                plan_from_canonical = self.get_canonical_component_name(plan_from_type) or plan_from_type
                plan_to_canonical = self.get_canonical_component_name(plan_to_type) or plan_to_type

                if (plan_from_canonical == from_type and
                    plan_to_canonical == to_type and
                    plan_conn.get("fromParam", plan_conn.get("from_param", "")) == from_param and
                    plan_conn.get("toParam", plan_conn.get("to_param", "")) == to_param):
                    has_connection = True
                    break

            if not has_connection and freq >= 10:  # åªå ±å‘Šé«˜é »é€£æ¥
                missing_connections.append({
                    "from": from_type,
                    "fromParam": from_param,
                    "to": to_type,
                    "toParam": to_param,
                    "frequency": freq
                })

        # ç”Ÿæˆå»ºè­°
        suggestions = []
        if missing_stages:
            suggestions.append(
                f"ç¼ºå°‘å¿…è¦éšæ®µ: {', '.join(missing_stages)}ã€‚"
                f"è«‹åƒè€ƒ {template['name']} æ¨™æº–æµç¨‹ã€‚"
            )
        if missing_components:
            suggestions.append(
                f"è«‹æ·»åŠ ä»¥ä¸‹çµ„ä»¶: {', '.join(missing_components)}"
            )
        if missing_connections:
            conn_strs = [
                f"{c['from']}.{c['fromParam']} â†’ {c['to']}.{c['toParam']} (freq={c['frequency']})"
                for c in missing_connections[:3]
            ]
            suggestions.append(
                f"å»ºè­°æ·»åŠ ä»¥ä¸‹é€£æ¥: {'; '.join(conn_strs)}"
            )

        return {
            "complete": len(missing_stages) == 0,
            "missing_stages": missing_stages,
            "missing_components": missing_components,
            "missing_connections": missing_connections,
            "warnings": [],
            "suggestions": suggestions
        }

    def auto_complete_workflow(
        self,
        plan: ExecutionPlan,
        workflow_type: str
    ) -> ExecutionPlan:
        """
        è‡ªå‹•è£œå…¨ç¼ºå¤±çš„å·¥ä½œæµç¨‹éšæ®µ

        é€™æ˜¯ä¸€å€‹å¢å¼·åŠŸèƒ½ï¼šç•¶æª¢æ¸¬åˆ°ç¼ºå¤±éšæ®µæ™‚ï¼Œ
        è‡ªå‹•å¾æ¨™æº–æ¨¡æ¿è£œå……çµ„ä»¶å’Œé€£æ¥ã€‚

        Args:
            plan: åŸå§‹è¨ˆç•«
            workflow_type: å·¥ä½œæµç¨‹é¡å‹

        Returns:
            è£œå…¨å¾Œçš„ ExecutionPlan
        """
        validation = self.validate_workflow_completeness(plan, workflow_type)

        if validation["complete"]:
            return plan  # å·²å®Œæ•´ï¼Œç„¡éœ€è£œå…¨

        template = self.STANDARD_WORKFLOWS.get(workflow_type)
        if not template:
            return plan

        # è¤‡è£½çµ„ä»¶å’Œé€£æ¥åˆ—è¡¨
        new_components = list(plan.components)
        new_connections = list(plan.connections)

        # æ ¹æ“šç¼ºå¤±éšæ®µè£œå……çµ„ä»¶
        existing_types = {c.get("type", "") for c in new_components}
        max_col = max((c.get("col", 0) for c in new_components), default=0)
        current_row = 0

        for stage_info in template.get("stages", []):
            stage_name = stage_info.get("stage", "")
            if stage_name not in validation["missing_stages"]:
                continue

            stage_components = stage_info.get("components", [])
            for comp_type in stage_components:
                if comp_type in existing_types:
                    continue

                # æ·»åŠ ç¼ºå¤±çš„çµ„ä»¶
                comp_id = comp_type.lower().replace(" ", "_").replace("-", "_")
                new_comp = {
                    "id": f"{comp_id}_auto",
                    "type": comp_type,
                    "nickname": comp_type.split("_")[-1] if "_" in comp_type else comp_type,
                    "col": max_col + 1,
                    "row": current_row,
                    "_auto_added": True,
                    "_reason": f"è£œå…¨ {stage_name} éšæ®µ"
                }
                new_components.append(new_comp)
                existing_types.add(comp_type)
                current_row += 1

                # åªæ·»åŠ ç¬¬ä¸€å€‹å»ºè­°çµ„ä»¶
                break

            max_col += 1

        # æ ¹æ“šç¼ºå¤±é€£æ¥è£œå……
        for missing_conn in validation["missing_connections"][:5]:  # æœ€å¤šè£œ 5 å€‹
            # æ‰¾åˆ°å°æ‡‰çš„çµ„ä»¶ ID
            from_id = None
            to_id = None

            for comp in new_components:
                comp_type = comp.get("type", "")
                canonical = self.get_canonical_component_name(comp_type) or comp_type

                if canonical == missing_conn["from"]:
                    from_id = comp.get("id")
                elif canonical == missing_conn["to"]:
                    to_id = comp.get("id")

            if from_id and to_id:
                new_conn = {
                    "from": from_id,
                    "fromParam": missing_conn["fromParam"],
                    "fromParamIndex": 0,
                    "to": to_id,
                    "toParam": missing_conn["toParam"],
                    "toParamIndex": 0,
                    "_auto_added": True
                }
                new_connections.append(new_conn)

        # æ›´æ–° warnings
        warnings = list(plan.warnings)
        if validation["missing_stages"]:
            warnings.append(
                f"å·²è‡ªå‹•è£œå…¨ç¼ºå¤±éšæ®µ: {', '.join(validation['missing_stages'])}"
            )

        # å»ºç«‹æ–°çš„ placement_info
        new_placement_info = {
            "components": new_components,
            "connections": new_connections,
            "layout": plan.placement_info.get("layout", {}) if plan.placement_info else {},
            "_meta": {
                **(plan.placement_info.get("_meta", {}) if plan.placement_info else {}),
                "auto_completed": True,
                "auto_completed_stages": validation["missing_stages"]
            }
        }

        return ExecutionPlan(
            success=plan.success,
            placement_info=new_placement_info,
            components=new_components,
            connections=new_connections,
            errors=plan.errors,
            warnings=warnings,
            generation_context={
                **plan.generation_context,
                "workflow_validation": validation
            },
            description=plan.description,
            patterns_used=plan.patterns_used,
            user_inputs=plan.user_inputs,
            component_groups=plan.component_groups
        )

    def _call_claude(self, prompt: str) -> str:
        """èª¿ç”¨ Claude API"""
        # ä½¿ç”¨ Anthropic Python SDK
        if hasattr(self.claude_client, 'messages'):
            # anthropic.Anthropic client
            response = self.claude_client.messages.create(
                model=self.model,
                max_tokens=4096,
                system=self.SYSTEM_PROMPT,
                messages=[{"role": "user", "content": prompt}]
            )
            return response.content[0].text

        # å‡è¨­æ˜¯å…¶ä»– client é¡å‹
        raise ValueError("Unsupported Claude client type")

    def _parse_response(self, response: str) -> ExecutionPlan:
        """è§£æ Claude å›æ‡‰"""
        try:
            # å˜—è©¦æå– JSON
            json_str = response

            # è™•ç† markdown ä»£ç¢¼å¡Š
            if "```json" in response:
                start = response.find("```json") + 7
                end = response.find("```", start)
                json_str = response[start:end].strip()
            elif "```" in response:
                start = response.find("```") + 3
                end = response.find("```", start)
                json_str = response[start:end].strip()

            data = json.loads(json_str)

            components = data.get("components", [])
            connections = data.get("connections", [])
            meta = data.get("_meta", {})

            # é©—è­‰åŸºæœ¬çµæ§‹
            if not components:
                return ExecutionPlan(
                    success=False,
                    errors=["Generated plan has no components"]
                )

            # å»ºç«‹ placement_info
            placement_info = {
                "components": components,
                "connections": connections,
                "layout": {},
                "_meta": {
                    "source": "claude_plan_generator",
                    "generated_at": datetime.now().isoformat(),
                    **meta
                }
            }

            return ExecutionPlan(
                success=True,
                placement_info=placement_info,
                components=components,
                connections=connections
            )

        except json.JSONDecodeError as e:
            return ExecutionPlan(
                success=False,
                errors=[f"Failed to parse JSON: {str(e)}"],
                generation_context={"raw_response": response[:500]}
            )
        except Exception as e:
            return ExecutionPlan(
                success=False,
                errors=[f"Failed to parse response: {str(e)}"]
            )

    def generate_from_template(
        self,
        template_name: str,
        parameters: Dict
    ) -> ExecutionPlan:
        """
        å¾æ¨¡æ¿ç”Ÿæˆè¨ˆç•« (ä¸éœ€è¦ Claude)

        ç”¨æ–¼å·²çŸ¥æ¨¡å¼çš„å¿«é€Ÿç”Ÿæˆ
        """
        patterns = self._connection_patterns.get("patterns", {})
        template = patterns.get(template_name)

        if not template:
            return ExecutionPlan(
                success=False,
                errors=[f"Template '{template_name}' not found"]
            )

        # TODO: å¯¦ä½œæ¨¡æ¿å±•é–‹é‚è¼¯
        return ExecutionPlan(
            success=False,
            errors=["Template expansion not yet implemented"]
        )


# =============================================================================
# ä¾¿æ·å‡½æ•¸
# =============================================================================

def generate_plan(
    user_input: str,
    knowledge: Dict,
    claude_client: Optional[Any] = None
) -> ExecutionPlan:
    """
    å¿«é€Ÿç”ŸæˆåŸ·è¡Œè¨ˆç•«

    Args:
        user_input: ç”¨æˆ¶è«‹æ±‚
        knowledge: çŸ¥è­˜åº«æœå°‹çµæœ
        claude_client: Claude å®¢æˆ¶ç«¯

    Returns:
        ExecutionPlan
    """
    generator = ClaudePlanGenerator(claude_client=claude_client)
    return generator.generate(user_input, knowledge)


# =============================================================================
# CLI
# =============================================================================

if __name__ == "__main__":
    import sys

    print("ClaudePlanGenerator - Layer 2 è¨ˆç•«ç”Ÿæˆå™¨")
    print("=" * 50)
    print("\næ³¨æ„: éœ€è¦é…ç½® Claude API å®¢æˆ¶ç«¯æ‰èƒ½å¯¦éš›ç”Ÿæˆ")
    print("\nUsage:")
    print("  from grasshopper_mcp import ClaudePlanGenerator")
    print("  generator = ClaudePlanGenerator(claude_client=client)")
    print("  plan = generator.generate(user_input, knowledge)")
