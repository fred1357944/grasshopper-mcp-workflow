#!/usr/bin/env python3
"""
Experience Database - ä¸‰å±¤çŸ¥è­˜æ¶æ§‹
==================================

Knowledge Hierarchy:
  ğŸ† Golden    - å®˜æ–¹å¯©æ ¸ã€å°ˆå®¶é©—è­‰ã€æ ¸å¿ƒç«¶çˆ­åŠ›
  ğŸŒ Community - ç¤¾ç¾¤è²¢ç»ã€æŠ•ç¥¨é©—è­‰ã€ç”Ÿæ…‹ç³»çµ±
  ğŸ“ Personal  - å€‹äººç´¯ç©ã€å³æ™‚å­¸ç¿’ã€å€‹äººåŒ–

çŸ¥è­˜æµå‹•:
  Personal â†’ (opt-in share) â†’ Community Pending â†’ (verified) â†’ Community â†’ (curated) â†’ Golden
"""

import json
import hashlib
from dataclasses import dataclass, field, asdict
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Dict, List, Optional, Any, Union


class KnowledgeSource(Enum):
    """çŸ¥è­˜ä¾†æºå±¤ç´š"""
    GOLDEN = "golden"          # ğŸ† å®˜æ–¹å¯©æ ¸
    COMMUNITY = "community"    # ğŸŒ ç¤¾ç¾¤é©—è­‰
    PERSONAL = "personal"      # ğŸ“ å€‹äººç¶“é©—
    NONE = "none"              # ç„¡åŒ¹é…


class KnowledgeStatus(Enum):
    """ç¤¾ç¾¤çŸ¥è­˜ç‹€æ…‹"""
    PENDING = "pending"        # ç­‰å¾…é©—è­‰
    VERIFIED = "verified"      # å·²é©—è­‰
    DEPRECATED = "deprecated"  # å·²æ£„ç”¨


@dataclass
class DomainKnowledge:
    """é ˜åŸŸçŸ¥è­˜ç‰‡æ®µ"""
    key: str                          # çŸ¥è­˜éµ (e.g., "solar_height_formula")
    value: str                        # çŸ¥è­˜å€¼ (e.g., "H â‰¤ 3.6(Sw+D)")
    source: str = "user_provided"     # ä¾†æº (user_provided, web_search, expert)
    context: str = ""                 # é©ç”¨æƒ…å¢ƒ
    confidence: float = 1.0           # ä¿¡å¿ƒåº¦


@dataclass
class LearnedPattern:
    """å­¸ç¿’åˆ°çš„é€£æ¥æ¨¡å¼"""
    pattern: str                      # e.g., "MeshBox.M â†’ FaceNormals.M"
    usage_count: int = 1
    success_count: int = 1
    last_used: str = ""


@dataclass
class Experience:
    """ç¶“é©—è¨˜éŒ„"""
    id: str
    timestamp: str

    # å•é¡Œæè¿°
    request: str                      # åŸå§‹è«‹æ±‚
    keywords: List[str] = field(default_factory=list)
    task_type: str = ""               # wasp, structural, solar, etc.

    # è§£æ±ºæ–¹æ¡ˆ
    solution: Dict = field(default_factory=dict)  # patterns_used, components, connections

    # é ˜åŸŸçŸ¥è­˜ (ç²¾è¯)
    domain_knowledge: List[Dict] = field(default_factory=list)

    # å­¸ç¿’åˆ°çš„æ¨¡å¼
    learned_patterns: List[str] = field(default_factory=list)

    # çµ±è¨ˆ
    usage_count: int = 1
    success_count: int = 1

    # ç¤¾ç¾¤ç‹€æ…‹ (åƒ… Community å±¤)
    status: str = "active"            # pending, verified, deprecated
    votes_up: int = 0
    votes_down: int = 0

    @property
    def success_rate(self) -> float:
        return self.success_count / max(self.usage_count, 1)


@dataclass
class KnowledgeResult:
    """çŸ¥è­˜æŸ¥è©¢çµæœ"""
    source: KnowledgeSource
    content: Optional[Experience] = None
    domain_knowledge: List[DomainKnowledge] = field(default_factory=list)
    reliability: str = ""
    action: str = ""  # ç•¶ source=NONE æ™‚çš„å»ºè­°å‹•ä½œ


class ExperienceDB:
    """
    ä¸‰å±¤ç¶“é©—çŸ¥è­˜åº«

    çµæ§‹:
      config/
        golden_knowledge/
          _index.json
          building_regulations/
          wasp_patterns/
          structural_systems/
        community_knowledge/
          _index.json
          pending/
          verified/
        personal_knowledge/
          {user_id}/
            experiences.json
            domain_knowledge.json
    """

    def __init__(
        self,
        storage_dir: Union[str, Path] = "config",
        user_id: str = "default"
    ):
        self.storage_dir = Path(storage_dir)
        self.user_id = user_id

        # ä¸‰å±¤ç›®éŒ„
        self.golden_dir = self.storage_dir / "golden_knowledge"
        self.community_dir = self.storage_dir / "community_knowledge"
        self.personal_dir = self.storage_dir / "personal_knowledge" / user_id

        # ç¢ºä¿ç›®éŒ„å­˜åœ¨
        self._ensure_directories()

        # è¼‰å…¥ç´¢å¼•
        self.golden_index = self._load_index(self.golden_dir)
        self.community_index = self._load_index(self.community_dir)
        self.personal_experiences = self._load_personal_experiences()
        self.personal_knowledge = self._load_personal_knowledge()

    def _ensure_directories(self):
        """ç¢ºä¿ç›®éŒ„çµæ§‹å­˜åœ¨"""
        dirs = [
            self.golden_dir,
            self.golden_dir / "building_regulations",
            self.golden_dir / "wasp_patterns",
            self.golden_dir / "structural_systems",
            self.community_dir / "pending",
            self.community_dir / "verified",
            self.personal_dir,
        ]
        for d in dirs:
            d.mkdir(parents=True, exist_ok=True)

    def _load_index(self, base_dir: Path) -> Dict:
        """è¼‰å…¥ç´¢å¼•"""
        index_path = base_dir / "_index.json"
        if index_path.exists():
            with open(index_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {"version": "1.0", "entries": [], "last_updated": ""}

    def _save_index(self, base_dir: Path, index: Dict):
        """å„²å­˜ç´¢å¼•"""
        index["last_updated"] = datetime.now().isoformat()
        index_path = base_dir / "_index.json"
        with open(index_path, 'w', encoding='utf-8') as f:
            json.dump(index, f, indent=2, ensure_ascii=False)

    def _load_personal_experiences(self) -> List[Experience]:
        """è¼‰å…¥å€‹äººç¶“é©—"""
        exp_path = self.personal_dir / "experiences.json"
        if exp_path.exists():
            with open(exp_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return [Experience(**e) for e in data.get("experiences", [])]
        return []

    def _save_personal_experiences(self):
        """å„²å­˜å€‹äººç¶“é©—"""
        exp_path = self.personal_dir / "experiences.json"
        data = {
            "version": "1.0",
            "user_id": self.user_id,
            "last_updated": datetime.now().isoformat(),
            "experiences": [asdict(e) for e in self.personal_experiences]
        }
        with open(exp_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

    def _load_personal_knowledge(self) -> List[DomainKnowledge]:
        """è¼‰å…¥å€‹äººé ˜åŸŸçŸ¥è­˜"""
        know_path = self.personal_dir / "domain_knowledge.json"
        if know_path.exists():
            with open(know_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return [DomainKnowledge(**k) for k in data.get("knowledge", [])]
        return []

    def _save_personal_knowledge(self):
        """å„²å­˜å€‹äººé ˜åŸŸçŸ¥è­˜"""
        know_path = self.personal_dir / "domain_knowledge.json"
        data = {
            "version": "1.0",
            "user_id": self.user_id,
            "last_updated": datetime.now().isoformat(),
            "knowledge": [asdict(k) for k in self.personal_knowledge]
        }
        with open(know_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

    # =========================================================================
    # æœå°‹ API
    # =========================================================================

    def search(
        self,
        query: str,
        keywords: Optional[List[str]] = None,
        task_type: Optional[str] = None
    ) -> KnowledgeResult:
        """
        ä¸‰å±¤çŸ¥è­˜æœå°‹ï¼ˆæŒ‰å„ªå…ˆé †åºï¼‰

        1. Goldenï¼ˆå®˜æ–¹ä¿è­‰å“è³ªï¼‰
        2. Community Verifiedï¼ˆç¾¤çœ¾é©—è­‰ï¼‰
        3. Personalï¼ˆè‡ªå·±ç”¨éï¼‰
        4. None â†’ éœ€è¦ HITL å”ä½œ
        """
        keywords = keywords or self._extract_keywords(query)

        # 1. æœå°‹ Golden
        golden = self._search_golden(keywords, task_type)
        if golden and golden.success_rate >= 0.8:
            return KnowledgeResult(
                source=KnowledgeSource.GOLDEN,
                content=golden,
                reliability="verified_by_experts",
            )

        # 2. æœå°‹ Community (Verified)
        community = self._search_community(keywords, task_type, verified_only=True)
        if community and community.success_rate >= 0.7:
            return KnowledgeResult(
                source=KnowledgeSource.COMMUNITY,
                content=community,
                reliability=f"used_by_{community.usage_count}_users",
            )

        # 3. æœå°‹ Personal
        personal = self._search_personal(keywords, task_type)
        if personal:
            return KnowledgeResult(
                source=KnowledgeSource.PERSONAL,
                content=personal,
                reliability="your_previous_solution",
            )

        # 4. éƒ½æ²’æœ‰
        return KnowledgeResult(
            source=KnowledgeSource.NONE,
            action="collaborate_with_user"
        )

    def search_knowledge(
        self,
        topic: str
    ) -> Optional[DomainKnowledge]:
        """
        æœå°‹é ˜åŸŸçŸ¥è­˜ç‰‡æ®µ

        ç”¨æ–¼ HITL å”ä½œæ™‚ï¼ŒæŸ¥æ‰¾ç›¸é—œçš„å·²çŸ¥çŸ¥è­˜
        """
        topic_lower = topic.lower()

        # æœå°‹å€‹äººçŸ¥è­˜
        for k in self.personal_knowledge:
            if topic_lower in k.key.lower() or topic_lower in k.value.lower():
                return k

        # TODO: æœå°‹ Golden å’Œ Community çš„çŸ¥è­˜ç‰‡æ®µ

        return None

    def _extract_keywords(self, text: str) -> List[str]:
        """æå–é—œéµå­—"""
        text_lower = text.lower()

        # é ˜åŸŸé—œéµå­—
        domain_keywords = {
            'wasp': ['wasp', 'é›¢æ•£', 'èšé›†', 'aggregation', 'part', 'module'],
            'structural': ['çµæ§‹', 'karamba', 'beam', 'column', 'æŸ±', 'æ¨‘'],
            'solar': ['æ—¥ç…§', 'ladybug', 'solar', 'shadow', 'é™°å½±'],
            'form_finding': ['kangaroo', 'æ‰¾å½¢', 'å¼µåŠ›', 'tensile', 'membrane'],
            'regulation': ['æ³•è¦', 'å»ºè”½ç‡', 'å®¹ç©ç‡', 'coverage', 'far'],
        }

        extracted = set()
        for category, kws in domain_keywords.items():
            for kw in kws:
                if kw.lower() in text_lower:
                    extracted.add(kw.lower())
                    extracted.add(category)

        return list(extracted)

    def _search_golden(
        self,
        keywords: List[str],
        task_type: Optional[str]
    ) -> Optional[Experience]:
        """æœå°‹ Golden çŸ¥è­˜åº«"""
        best_match = None
        best_score = 0.0

        for entry in self.golden_index.get("entries", []):
            # è¨ˆç®—åŒ¹é…åˆ†æ•¸
            entry_keywords = set(k.lower() for k in entry.get("keywords", []))
            query_keywords = set(k.lower() for k in keywords)

            overlap = entry_keywords & query_keywords
            if not overlap:
                continue

            score = len(overlap) / max(len(query_keywords), 1)

            # task_type åŠ åˆ†
            if task_type and entry.get("task_type") == task_type:
                score *= 1.2

            if score > best_score:
                best_score = score
                # è¼‰å…¥å®Œæ•´ç¶“é©—
                exp_path = self.golden_dir / entry.get("path", "")
                if exp_path.exists():
                    with open(exp_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        best_match = self._dict_to_experience(data)

        return best_match

    def _dict_to_experience(self, data: Dict) -> Experience:
        """å°‡å­—å…¸è½‰æ›ç‚º Experienceï¼Œéæ¿¾é¡å¤–æ¬„ä½"""
        # Experience æ”¯æ´çš„æ¬„ä½
        valid_fields = {
            'id', 'timestamp', 'request', 'keywords', 'task_type',
            'solution', 'domain_knowledge', 'learned_patterns',
            'usage_count', 'success_count', 'status', 'votes_up', 'votes_down'
        }
        filtered = {k: v for k, v in data.items() if k in valid_fields}
        return Experience(**filtered)

    def _search_community(
        self,
        keywords: List[str],
        task_type: Optional[str],
        verified_only: bool = True
    ) -> Optional[Experience]:
        """æœå°‹ Community çŸ¥è­˜åº«"""
        search_dir = self.community_dir / ("verified" if verified_only else "pending")

        if not search_dir.exists():
            return None

        best_match = None
        best_score = 0.0

        for exp_file in search_dir.glob("*.json"):
            try:
                with open(exp_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    exp = self._dict_to_experience(data)

                # è¨ˆç®—åŒ¹é…åˆ†æ•¸
                exp_keywords = set(k.lower() for k in exp.keywords)
                query_keywords = set(k.lower() for k in keywords)

                overlap = exp_keywords & query_keywords
                if not overlap:
                    continue

                score = len(overlap) / max(len(query_keywords), 1)
                score *= exp.success_rate  # æˆåŠŸç‡åŠ æ¬Š

                if score > best_score:
                    best_score = score
                    best_match = exp

            except Exception:
                continue

        return best_match

    def _search_personal(
        self,
        keywords: List[str],
        task_type: Optional[str]
    ) -> Optional[Experience]:
        """æœå°‹å€‹äººç¶“é©—"""
        best_match = None
        best_score = 0.0

        for exp in self.personal_experiences:
            exp_keywords = set(k.lower() for k in exp.keywords)
            query_keywords = set(k.lower() for k in keywords)

            overlap = exp_keywords & query_keywords
            if not overlap:
                continue

            score = len(overlap) / max(len(query_keywords), 1)

            if score > best_score:
                best_score = score
                best_match = exp

        return best_match

    # =========================================================================
    # å­¸ç¿’ API
    # =========================================================================

    def learn(
        self,
        request: str,
        solution: Dict,
        domain_knowledge: Optional[List[Dict]] = None,
        patterns_used: Optional[List[str]] = None
    ) -> Experience:
        """
        å¾æˆåŠŸæ¡ˆä¾‹å­¸ç¿’

        è‡ªå‹•å„²å­˜åˆ° Personal å±¤
        """
        # ç”Ÿæˆ ID
        exp_id = self._generate_id(request)

        # æå–é—œéµå­—
        keywords = self._extract_keywords(request)

        # æ¨æ–·ä»»å‹™é¡å‹
        task_type = self._infer_task_type(keywords)

        # å‰µå»ºç¶“é©—
        exp = Experience(
            id=exp_id,
            timestamp=datetime.now().isoformat(),
            request=request,
            keywords=keywords,
            task_type=task_type,
            solution=solution,
            domain_knowledge=domain_knowledge or [],
            learned_patterns=patterns_used or [],
        )

        # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨é¡ä¼¼ç¶“é©—
        existing = self._find_similar_experience(exp)
        if existing:
            # æ›´æ–°ç¾æœ‰ç¶“é©—
            existing.usage_count += 1
            existing.success_count += 1
            # åˆä½µçŸ¥è­˜
            self._merge_knowledge(existing, exp)
        else:
            # æ–°å¢ç¶“é©—
            self.personal_experiences.append(exp)

        # å­¸ç¿’é ˜åŸŸçŸ¥è­˜
        if domain_knowledge:
            for dk in domain_knowledge:
                self._learn_domain_knowledge(DomainKnowledge(**dk))

        # å„²å­˜
        self._save_personal_experiences()
        self._save_personal_knowledge()

        return exp

    def record_failure(
        self,
        request: str,
        error: str,
        diagnostic: Optional[Dict] = None
    ):
        """è¨˜éŒ„å¤±æ•—æ¡ˆä¾‹"""
        # æ‰¾åˆ°ç›¸é—œç¶“é©—
        keywords = self._extract_keywords(request)
        exp = self._search_personal(keywords, None)

        if exp:
            exp.usage_count += 1
            # ä¸å¢åŠ  success_count
            self._save_personal_experiences()

    def _generate_id(self, text: str) -> str:
        """ç”Ÿæˆå”¯ä¸€ ID"""
        hash_input = f"{text}_{datetime.now().isoformat()}"
        return hashlib.md5(hash_input.encode()).hexdigest()[:12]

    def _infer_task_type(self, keywords: List[str]) -> str:
        """æ¨æ–·ä»»å‹™é¡å‹"""
        type_keywords = {
            'wasp': ['wasp', 'aggregation', 'èšé›†', 'part'],
            'structural': ['structural', 'karamba', 'çµæ§‹', 'beam'],
            'solar': ['solar', 'ladybug', 'æ—¥ç…§', 'shadow'],
            'form_finding': ['kangaroo', 'tensile', 'å¼µåŠ›', 'membrane'],
            'regulation': ['regulation', 'æ³•è¦', 'å»ºè”½ç‡', 'å®¹ç©ç‡'],
        }

        keywords_lower = set(k.lower() for k in keywords)

        for task_type, type_kws in type_keywords.items():
            if any(kw in keywords_lower for kw in type_kws):
                return task_type

        return "general"

    def _find_similar_experience(self, new_exp: Experience) -> Optional[Experience]:
        """æ‰¾ç›¸ä¼¼ç¶“é©—"""
        for exp in self.personal_experiences:
            # é—œéµå­—é‡ç–Šåº¦
            overlap = set(exp.keywords) & set(new_exp.keywords)
            if len(overlap) >= len(new_exp.keywords) * 0.7:
                return exp
        return None

    def _merge_knowledge(self, existing: Experience, new_exp: Experience):
        """åˆä½µçŸ¥è­˜"""
        # åˆä½µé ˜åŸŸçŸ¥è­˜
        existing_keys = {dk.get("key") for dk in existing.domain_knowledge}
        for dk in new_exp.domain_knowledge:
            if dk.get("key") not in existing_keys:
                existing.domain_knowledge.append(dk)

        # åˆä½µæ¨¡å¼
        existing_patterns = set(existing.learned_patterns)
        for p in new_exp.learned_patterns:
            if p not in existing_patterns:
                existing.learned_patterns.append(p)

    def _learn_domain_knowledge(self, knowledge: DomainKnowledge):
        """å­¸ç¿’é ˜åŸŸçŸ¥è­˜ç‰‡æ®µ"""
        # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
        for k in self.personal_knowledge:
            if k.key == knowledge.key:
                # æ›´æ–°ä¿¡å¿ƒåº¦
                k.confidence = min(k.confidence + 0.1, 1.0)
                return

        # æ–°å¢
        self.personal_knowledge.append(knowledge)

    # =========================================================================
    # çŸ¥è­˜æ™‰å‡ API
    # =========================================================================

    def share_to_community(self, experience_id: str) -> bool:
        """
        åˆ†äº«ç¶“é©—åˆ°ç¤¾ç¾¤ (opt-in)

        Personal â†’ Community Pending
        """
        # æ‰¾åˆ°ç¶“é©—
        exp = None
        for e in self.personal_experiences:
            if e.id == experience_id:
                exp = e
                break

        if not exp:
            return False

        # åŒ¿ååŒ–è™•ç†
        shared_exp = Experience(
            id=self._generate_id(f"community_{exp.id}"),
            timestamp=datetime.now().isoformat(),
            request=exp.request,
            keywords=exp.keywords,
            task_type=exp.task_type,
            solution=exp.solution,
            domain_knowledge=exp.domain_knowledge,
            learned_patterns=exp.learned_patterns,
            status="pending",
        )

        # å„²å­˜åˆ° Community Pending
        pending_path = self.community_dir / "pending" / f"{shared_exp.id}.json"
        with open(pending_path, 'w', encoding='utf-8') as f:
            json.dump(asdict(shared_exp), f, indent=2, ensure_ascii=False)

        return True

    def verify_community_experience(
        self,
        experience_id: str,
        approved: bool = True
    ) -> bool:
        """
        é©—è­‰ç¤¾ç¾¤ç¶“é©—ï¼ˆç®¡ç†å“¡åŠŸèƒ½ï¼‰

        Pending â†’ Verified / Deprecated
        """
        pending_path = self.community_dir / "pending" / f"{experience_id}.json"

        if not pending_path.exists():
            return False

        with open(pending_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        if approved:
            # ç§»å‹•åˆ° verified
            data["status"] = "verified"
            verified_path = self.community_dir / "verified" / f"{experience_id}.json"
            with open(verified_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)

        # åˆªé™¤ pending
        pending_path.unlink()

        return True


# =============================================================================
# Golden Knowledge Builder (é–‹ç™¼å·¥å…·)
# =============================================================================

class GoldenKnowledgeBuilder:
    """
    é»ƒé‡‘çŸ¥è­˜æ§‹å»ºå™¨

    ç”¨æ–¼å‰µå»ºå®˜æ–¹å¯©æ ¸çš„é»ƒé‡‘æ³•å‰‡
    """

    def __init__(self, golden_dir: Path):
        self.golden_dir = golden_dir
        self.index_path = golden_dir / "_index.json"

    def add_golden_rule(
        self,
        category: str,          # building_regulations, wasp_patterns, etc.
        name: str,
        description: str,
        keywords: List[str],
        solution: Dict,
        domain_knowledge: List[Dict],
        expert_verified: bool = True
    ) -> str:
        """æ–°å¢é»ƒé‡‘æ³•å‰‡"""

        # ç”Ÿæˆ ID
        rule_id = f"golden_{category}_{name}".replace(" ", "_").lower()

        # å‰µå»ºç¶“é©—
        exp = Experience(
            id=rule_id,
            timestamp=datetime.now().isoformat(),
            request=description,
            keywords=keywords,
            task_type=category,
            solution=solution,
            domain_knowledge=domain_knowledge,
            usage_count=100,  # é è¨­é«˜ä½¿ç”¨é‡
            success_count=100,
            status="golden",
        )

        # å„²å­˜
        category_dir = self.golden_dir / category
        category_dir.mkdir(parents=True, exist_ok=True)

        exp_path = category_dir / f"{name}.json"
        with open(exp_path, 'w', encoding='utf-8') as f:
            json.dump(asdict(exp), f, indent=2, ensure_ascii=False)

        # æ›´æ–°ç´¢å¼•
        self._update_index(
            category=category,
            name=name,
            path=str(exp_path.relative_to(self.golden_dir)),
            keywords=keywords,
            task_type=category,
            expert_verified=expert_verified
        )

        return rule_id

    def _update_index(self, **entry):
        """æ›´æ–°ç´¢å¼•"""
        if self.index_path.exists():
            with open(self.index_path, 'r', encoding='utf-8') as f:
                index = json.load(f)
        else:
            index = {"version": "1.0", "entries": []}

        # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
        for i, e in enumerate(index["entries"]):
            if e.get("name") == entry["name"]:
                index["entries"][i] = entry
                break
        else:
            index["entries"].append(entry)

        index["last_updated"] = datetime.now().isoformat()

        with open(self.index_path, 'w', encoding='utf-8') as f:
            json.dump(index, f, indent=2, ensure_ascii=False)


# =============================================================================
# CLI Test
# =============================================================================

if __name__ == "__main__":
    print("Experience Database - ä¸‰å±¤çŸ¥è­˜æ¶æ§‹æ¸¬è©¦")
    print("=" * 60)

    # åˆå§‹åŒ–
    db = ExperienceDB(storage_dir="config", user_id="test_user")

    # æ¸¬è©¦å­¸ç¿’
    print("\n1. æ¸¬è©¦å­¸ç¿’åŠŸèƒ½...")
    exp = db.learn(
        request="åšä¸€å€‹ WASP ç«‹æ–¹é«”èšé›†",
        solution={
            "patterns_used": ["wasp_cube_aggregation"],
            "components": ["Mesh Box", "WASP Part", "WASP Aggregation"],
        },
        domain_knowledge=[
            {"key": "wasp_geo_type", "value": "GEO å¿…é ˆæ˜¯ Mesh ä¸èƒ½æ˜¯ Brep", "source": "user_provided"}
        ],
        patterns_used=["MeshBox.M â†’ WASPPart.GEO", "WASPPart.PART â†’ WASPAggregation.PART"]
    )
    print(f"  å­¸ç¿’æˆåŠŸ: {exp.id}")

    # æ¸¬è©¦æœå°‹
    print("\n2. æ¸¬è©¦æœå°‹åŠŸèƒ½...")
    result = db.search("wasp èšé›†è¨­è¨ˆ")
    print(f"  ä¾†æº: {result.source.value}")
    print(f"  å¯é åº¦: {result.reliability}")
    if result.content:
        print(f"  åŒ¹é…: {result.content.request}")

    # æ¸¬è©¦çŸ¥è­˜æœå°‹
    print("\n3. æ¸¬è©¦çŸ¥è­˜æœå°‹...")
    knowledge = db.search_knowledge("wasp_geo")
    if knowledge:
        print(f"  æ‰¾åˆ°: {knowledge.key} = {knowledge.value}")
    else:
        print("  æœªæ‰¾åˆ°ç›¸é—œçŸ¥è­˜")

    print("\n" + "=" * 60)
    print("æ¸¬è©¦å®Œæˆï¼")
