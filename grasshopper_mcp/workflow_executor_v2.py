#!/usr/bin/env python3
"""
WorkflowExecutor v2.1 - æ•´åˆç‰ˆ
================================

æ•´åˆï¼š
1. å…©éšæ®µ Routerï¼ˆReference Match + ä¸‰ç¶­è©•ä¼°ï¼‰
2. å„ªåŒ–é©—è­‰é †åºï¼ˆPre-Check â†’ Semantic Reviewï¼‰
3. Reference-First + Dual-Mode çµ±ä¸€å…¥å£

æµç¨‹ï¼š
    ç”¨æˆ¶è«‹æ±‚ â†’ Router â†’ Reference/Meta-Agent â†’ Validate â†’ Execute â†’ Archive

Usage:
    executor = WorkflowExecutor(config_dir="reference_library")
    result = await executor.run("åšä¸€å€‹ WASP ç«‹æ–¹é«”èšé›†")
"""

import json
import asyncio
from enum import Enum
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any, Callable, Awaitable
from pathlib import Path
from datetime import datetime

# Learning Agent æ•´åˆ
from .knowledge_base import ConnectionKnowledgeBase
from .learning_agent import LearningAgent

# Vision è¨ºæ–·æ•´åˆ
from .vision_diagnostic_client import (
    VisionDiagnosticClient,
    ExecutionDiagnosticHelper,
    DiagnosticLevel,
    DiagnosticResult
)

# Component Validator (Validation-First Architecture)
from .component_validator import (
    ComponentValidator,
    ValidationStatus,
    ValidationReport as ComponentValidationReport,
)


# ============================================================================
# Enums & Data Classes
# ============================================================================

class ExecutionMode(Enum):
    """åŸ·è¡Œæ¨¡å¼"""
    REFERENCE = "reference"      # æœ‰ Golden Config
    WORKFLOW = "workflow"        # ä¸‰ç¶­è©•ä¼°é€šé
    META_AGENT = "meta_agent"    # éœ€è¦å½ˆæ€§è™•ç†


class WorkflowPhase(Enum):
    """å·¥ä½œæµç¨‹éšæ®µ"""
    ROUTE = "route"
    SEARCH = "search"
    CONFIRM = "confirm"
    PRE_CHECK = "pre_check"           # å…ˆåšèªæ³•æª¢æŸ¥
    SEMANTIC_REVIEW = "semantic_review"  # é€šéå¾Œå†åšèªç¾©å¯©æŸ¥
    EXECUTE = "execute"
    ARCHIVE = "archive"
    COMPLETE = "complete"
    FAILED = "failed"


class RiskLevel(Enum):
    """é¢¨éšªç­‰ç´š"""
    INFO = "info"
    WARNING = "warning"
    CRITICAL = "critical"


@dataclass
class RouterDecision:
    """è·¯ç”±æ±ºç­–çµæœ"""
    mode: ExecutionMode
    confidence: float
    reason: str
    stage: str  # "reference_match" or "three_dimension"
    reference: Optional[Dict] = None
    partial_matches: List[Dict] = field(default_factory=list)
    scores: Dict[str, float] = field(default_factory=dict)


@dataclass
class ValidationResult:
    """é©—è­‰çµæœ"""
    passed: bool
    phase: str  # "pre_check" or "semantic_review"
    issues: List[Dict] = field(default_factory=list)
    risk_level: RiskLevel = RiskLevel.INFO
    data_flow_trace: Optional[str] = None  # Mermaid æ ¼å¼


@dataclass
class ExecutionResult:
    """åŸ·è¡Œçµæœ"""
    success: bool
    mode: ExecutionMode
    phase: WorkflowPhase
    config_used: Optional[Dict] = None
    validation: Optional[ValidationResult] = None
    component_validation: Optional[ComponentValidationReport] = None  # çµ„ä»¶é©—è­‰å ±å‘Š
    errors: List[str] = field(default_factory=list)
    learned: bool = False
    diagnostic: Optional[Dict] = None  # Vision è¨ºæ–·çµæœ


# ============================================================================
# Two-Stage Router
# ============================================================================

class IntegratedRouter:
    """
    å…©éšæ®µ Router
    
    Stage 1: Reference Matchï¼ˆæœå°‹ golden/ + variations/ï¼‰
    Stage 2: ä¸‰ç¶­è©•ä¼°ï¼ˆIntent + Tool + Patternï¼‰
    """
    
    # é ˜åŸŸé—œéµå­—
    DOMAIN_KEYWORDS: Dict[str, List[str]] = {
        'wasp': ['wasp', 'é›¢æ•£', 'èšé›†', 'aggregation', 'part', 'module', 'æ¨¡çµ„', 'stochastic', 'ç«‹æ–¹é«”', 'cube'],
        'karamba': ['karamba', 'çµæ§‹', 'åˆ†æ', 'beam', 'shell', 'structural', 'fea', 'æ¨‘'],
        'ladybug': ['ladybug', 'honeybee', 'æ—¥ç…§', 'èƒ½æº', 'radiation', 'solar', 'energy', 'é®é™½'],
        'kangaroo': ['kangaroo', 'ç‰©ç†', 'æ¨¡æ“¬', 'physics', 'simulation', 'æ‰¾å½¢', 'å½¢æ…‹', 'form finding', 'å¼µåŠ›', 'tensile', 'è†œ', 'membrane', 'fabric', 'tension'],
        'geometry': ['voronoi', 'mesh', 'surface', 'curve', 'point', 'brep', 'ç¶²æ ¼', 'æ›²é¢'],
    }
    
    def __init__(
        self,
        reference_library_path: Path,
        pattern_library_path: Optional[Path] = None
    ):
        self.ref_path = Path(reference_library_path)
        self.pattern_path = pattern_library_path
        
        # é–¾å€¼é…ç½®
        self.thresholds = {
            'reference_direct': 0.8,    # Stage 1: ç›´æ¥èµ° Reference
            'workflow_min': 0.8,        # Stage 2: ä¸‰ç¶­è©•ä¼°é–¾å€¼
        }
        
        # Stage 2 æ¬Šé‡
        self.weights = {
            'intent': 0.4,
            'tool': 0.35,
            'pattern': 0.25,
        }
        
        # è¼‰å…¥ç´¢å¼•
        self.reference_index = self._load_reference_index()
    
    def _load_reference_index(self) -> Dict:
        """è¼‰å…¥ Reference Library ç´¢å¼•"""
        index_path = self.ref_path / "_index.json"
        
        if index_path.exists():
            with open(index_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        
        # è‡ªå‹•å»ºç«‹ç´¢å¼•
        return self._build_reference_index()
    
    def _build_reference_index(self) -> Dict:
        """å»ºç«‹ Reference ç´¢å¼•"""
        index = {"entries": [], "version": "2.1"}
        
        if not self.ref_path.exists():
            return index
        
        for category_dir in self.ref_path.iterdir():
            if category_dir.is_dir() and not category_dir.name.startswith("_"):
                # è®€å– metadata.json
                metadata_path = category_dir / "metadata.json"
                category_meta = {}
                if metadata_path.exists():
                    with open(metadata_path, 'r', encoding='utf-8') as f:
                        category_meta = json.load(f)
                
                # æœå°‹ golden/
                golden_dir = category_dir / "golden"
                if golden_dir.exists():
                    for config_file in golden_dir.glob("*.json"):
                        entry = self._index_config_file(config_file, category_dir.name, category_meta)
                        if entry:
                            index["entries"].append(entry)
                
                # æœå°‹ variations/
                variations_dir = category_dir / "variations"
                if variations_dir.exists():
                    for config_file in variations_dir.glob("*.json"):
                        entry = self._index_config_file(config_file, category_dir.name, category_meta, is_variation=True)
                        if entry:
                            index["entries"].append(entry)
        
        # å„²å­˜ç´¢å¼•
        try:
            with open(self.ref_path / "_index.json", 'w', encoding='utf-8') as f:
                json.dump(index, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"Warning: Failed to save index: {e}")
        
        return index
    
    def _index_config_file(
        self, 
        config_file: Path, 
        category: str, 
        category_meta: Dict,
        is_variation: bool = False
    ) -> Optional[Dict]:
        """ç´¢å¼•å–®å€‹é…ç½®æª”æ¡ˆ"""
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            meta = config.get("_meta", {})
            config_name = config_file.stem
            
            # æª¢æŸ¥ metadata.json ä¸­çš„å„ªå…ˆç´šè¨­å®š
            config_override = category_meta.get("configs", {}).get(config_name, {})
            
            # æ±ºå®š confidence
            if config_override.get("status") == "DEPRECATED":
                confidence = config_override.get("confidence", 0.3)
            elif config_override.get("preferred", False):
                confidence = config_override.get("confidence", 1.0)
            else:
                confidence = meta.get("confidence", 0.9 if is_variation else 1.0)
            
            return {
                "path": str(config_file),
                "category": category,
                "name": meta.get("name", config_name),
                "keywords": meta.get("keywords", []),
                "confidence": confidence,
                "verified": meta.get("verified", False),
                "description": meta.get("description", ""),
                "is_variation": is_variation,
                "deprecated": config_override.get("status") == "DEPRECATED",
                "preferred": config_override.get("preferred", False),
            }
        except Exception as e:
            print(f"Warning: Failed to index {config_file}: {e}")
            return None
    
    def route(self, user_input: str, context: Optional[Dict] = None) -> RouterDecision:
        """
        ä¸»è·¯ç”±é‚è¼¯ï¼ˆå…©éšæ®µï¼‰
        
        Args:
            user_input: ç”¨æˆ¶è«‹æ±‚
            context: é¡å¤–ä¸Šä¸‹æ–‡
            
        Returns:
            RouterDecision
        """
        context = context or {}
        
        # ========== Stage 1: Reference Match ==========
        keywords = self._extract_keywords(user_input)
        reference_result = self._search_reference(keywords)
        
        if reference_result and reference_result["confidence"] >= self.thresholds['reference_direct']:
            # æª¢æŸ¥æ˜¯å¦è¢« deprecated
            if reference_result.get("deprecated"):
                # å˜—è©¦æ‰¾ preferred ç‰ˆæœ¬
                preferred = self._find_preferred_alternative(reference_result)
                if preferred:
                    reference_result = preferred
            
            return RouterDecision(
                mode=ExecutionMode.REFERENCE,
                confidence=reference_result["confidence"],
                reason=f"âœ… æ‰¾åˆ° Golden Config: {reference_result['name']}",
                stage="reference_match",
                reference=reference_result,
                scores={"reference_match": reference_result["confidence"]}
            )
        
        # ========== Stage 2: ä¸‰ç¶­è©•ä¼° ==========
        intent_score = self._assess_intent_clarity(user_input, keywords)
        tool_score = self._assess_tool_availability(keywords, context)
        pattern_score = self._assess_pattern_match(keywords)
        
        total_score = (
            intent_score * self.weights['intent'] +
            tool_score * self.weights['tool'] +
            pattern_score * self.weights['pattern']
        )
        
        scores = {
            "intent": intent_score,
            "tool": tool_score,
            "pattern": pattern_score,
            "total": total_score,
            "reference_match": reference_result["confidence"] if reference_result else 0.0
        }
        
        if total_score >= self.thresholds['workflow_min']:
            return RouterDecision(
                mode=ExecutionMode.WORKFLOW,
                confidence=total_score,
                reason=f"ä¸‰ç¶­è©•ä¼°é€šé: æ„åœ–{intent_score:.0%}ã€å·¥å…·{tool_score:.0%}ã€æ¨¡å¼{pattern_score:.0%}",
                stage="three_dimension",
                reference=reference_result,
                scores=scores
            )
        else:
            return RouterDecision(
                mode=ExecutionMode.META_AGENT,
                confidence=total_score,
                reason=self._explain_meta_agent_reason(intent_score, tool_score, pattern_score),
                stage="meta_agent",
                partial_matches=[reference_result] if reference_result else [],
                scores=scores
            )
    
    def _extract_keywords(self, text: str) -> List[str]:
        """æå–é—œéµå­—"""
        text_lower = text.lower()
        extracted = set()
        
        for category, kws in self.DOMAIN_KEYWORDS.items():
            for kw in kws:
                if kw.lower() in text_lower:
                    extracted.add(kw.lower())
        
        return list(extracted)
    
    def _search_reference(self, keywords: List[str]) -> Optional[Dict]:
        """æœå°‹ Reference Library"""
        if not keywords:
            return None
        
        query_keywords = set(kw.lower() for kw in keywords)
        best_match = None
        best_score = 0.0
        
        for entry in self.reference_index.get("entries", []):
            # è·³é deprecatedï¼ˆé™¤éæ²’æœ‰å…¶ä»–é¸æ“‡ï¼‰
            if entry.get("deprecated") and best_match:
                continue
            
            entry_keywords = set(kw.lower() for kw in entry.get("keywords", []))
            overlap = entry_keywords & query_keywords
            
            if overlap:
                overlap_ratio = len(overlap) / max(len(query_keywords), 1)
                config_confidence = entry.get("confidence", 1.0)
                
                # preferred åŠ åˆ†
                if entry.get("preferred"):
                    config_confidence = min(config_confidence * 1.1, 1.0)
                
                score = overlap_ratio * config_confidence
                
                if score > best_score:
                    best_score = score
                    best_match = {**entry, "confidence": score, "matched_keywords": list(overlap)}
        
        return best_match
    
    def _find_preferred_alternative(self, deprecated_entry: Dict) -> Optional[Dict]:
        """æ‰¾ preferred æ›¿ä»£ç‰ˆæœ¬"""
        category = deprecated_entry.get("category")
        
        for entry in self.reference_index.get("entries", []):
            if (entry.get("category") == category and 
                entry.get("preferred") and 
                not entry.get("deprecated")):
                return entry
        
        return None
    
    def _assess_intent_clarity(self, user_input: str, keywords: List[str]) -> float:
        """è©•ä¼°æ„åœ–æ¸…æ™°åº¦"""
        score = 0.0
        
        # æœ‰å…·é«”æ’ä»¶åç¨±
        plugin_names = ['wasp', 'karamba', 'ladybug', 'kangaroo', 'galapagos']
        if any(p in user_input.lower() for p in plugin_names):
            score += 0.4
        
        # æœ‰å¹¾ä½•é¡å‹
        geo_types = ['cube', 'sphere', 'mesh', 'curve', 'surface', 'ç«‹æ–¹é«”', 'çƒ', 'æ›²é¢']
        if any(g in user_input.lower() for g in geo_types):
            score += 0.3
        
        # æœ‰å‹•ä½œè©
        actions = ['åš', 'create', 'å»ºç«‹', 'ç”Ÿæˆ', 'åˆ†æ', 'analyze', 'èšé›†', 'aggregate']
        if any(a in user_input.lower() for a in actions):
            score += 0.2
        
        # é—œéµå­—æ•¸é‡åŠ åˆ†
        if len(keywords) >= 3:
            score += 0.1
        
        return min(score, 1.0)
    
    def _assess_tool_availability(self, keywords: List[str], context: Dict) -> float:
        """è©•ä¼°å·¥å…·å¯ç”¨æ€§"""
        # ç°¡åŒ–ç‰ˆï¼šå‡è¨­å¸¸è¦‹æ’ä»¶éƒ½å¯ç”¨
        available_plugins = {'wasp', 'karamba', 'ladybug', 'kangaroo', 'galapagos'}
        
        matched = sum(1 for kw in keywords if kw.lower() in available_plugins)
        
        if not keywords:
            return 0.5
        
        return min(matched / len(keywords) + 0.5, 1.0)
    
    def _assess_pattern_match(self, keywords: List[str]) -> float:
        """è©•ä¼°æ¨¡å¼åŒ¹é…åº¦"""
        # ä½¿ç”¨ Reference æœå°‹çµæœä½œç‚º pattern match
        result = self._search_reference(keywords)
        return result["confidence"] if result else 0.0
    
    def _explain_meta_agent_reason(self, intent: float, tool: float, pattern: float) -> str:
        """è§£é‡‹ç‚ºä»€éº¼éœ€è¦ Meta-Agent"""
        reasons = []
        
        if intent < 0.6:
            reasons.append(f"éœ€æ±‚ä¸å¤ æ˜ç¢ºï¼ˆ{intent:.0%}ï¼‰")
        if tool < 0.7:
            reasons.append(f"éƒ¨åˆ†å·¥å…·ç¼ºå¤±ï¼ˆ{tool:.0%}ï¼‰")
        if pattern < 0.5:
            reasons.append(f"æ²’æœ‰åŒ¹é…æ¨¡å¼ï¼ˆ{pattern:.0%}ï¼‰")
        
        return "ï¼Œ".join(reasons) if reasons else "ç¶œåˆè©•ä¼°éœ€è¦å½ˆæ€§è™•ç†"


# ============================================================================
# Validators
# ============================================================================

class PreExecutionChecker:
    """
    Pre-Execution Checkerï¼ˆHardcoded è¦å‰‡ï¼‰
    
    å¿«é€Ÿã€ç¢ºå®šæ€§çš„èªæ³•æª¢æŸ¥
    """
    
    # å·²çŸ¥çš„å±éšªæ¨¡å¼
    DANGEROUS_PATTERNS = [
        {
            "component": "Mesh Box",
            "params": ["X", "Y", "Z"],
            "check": "value_too_high",
            "threshold": 20,
            "risk": RiskLevel.CRITICAL,
            "message": "Mesh Box çš„ X/Y/Z æ˜¯ç´°åˆ†æ•¸é‡ï¼Œä¸æ˜¯å°ºå¯¸ã€‚å€¼éé«˜æœƒå°è‡´è³‡æ–™çˆ†ç‚¸ã€‚"
        },
        {
            "component": "Divide Curve",
            "params": ["Count"],
            "check": "value_too_high",
            "threshold": 1000,
            "risk": RiskLevel.WARNING,
            "message": "åˆ†å‰²æ•¸é‡éé«˜å¯èƒ½å°è‡´æ•ˆèƒ½å•é¡Œã€‚"
        }
    ]
    
    def check(self, config: Dict) -> ValidationResult:
        """åŸ·è¡Œèªæ³•æª¢æŸ¥"""
        issues = []
        max_risk = RiskLevel.INFO
        
        components = config.get("components", [])
        
        for comp in components:
            comp_type = comp.get("type", "")
            props = comp.get("properties", {})
            
            for pattern in self.DANGEROUS_PATTERNS:
                if pattern["component"].lower() in comp_type.lower():
                    for param in pattern["params"]:
                        value = props.get(param.lower()) or props.get(param)
                        
                        if value is not None:
                            if pattern["check"] == "value_too_high" and value > pattern["threshold"]:
                                issues.append({
                                    "component": comp.get("nickname", comp_type),
                                    "param": param,
                                    "value": value,
                                    "threshold": pattern["threshold"],
                                    "risk": pattern["risk"].value,
                                    "message": pattern["message"]
                                })
                                
                                if pattern["risk"].value == "critical":
                                    max_risk = RiskLevel.CRITICAL
                                elif pattern["risk"].value == "warning" and max_risk != RiskLevel.CRITICAL:
                                    max_risk = RiskLevel.WARNING
        
        return ValidationResult(
            passed=max_risk != RiskLevel.CRITICAL,
            phase="pre_check",
            issues=issues,
            risk_level=max_risk
        )


class SemanticReviewer:
    """
    Semantic Reviewerï¼ˆLLM èªç¾©å¯©æŸ¥ï¼‰
    
    è³‡æ–™æµè¿½è¹¤ã€èªç¾©è¡çªæª¢æ¸¬
    """
    
    def __init__(self, llm_client: Optional[Any] = None):
        self.llm = llm_client
    
    async def review(self, config: Dict, user_intent: str) -> ValidationResult:
        """åŸ·è¡Œèªç¾©å¯©æŸ¥"""
        
        # å¦‚æœæ²’æœ‰ LLM clientï¼Œä½¿ç”¨è¦å‰‡åŒ–å¯©æŸ¥
        if self.llm is None:
            return self._rule_based_review(config, user_intent)
        
        # LLM å¯©æŸ¥
        prompt = self._build_review_prompt(config, user_intent)
        response = await self.llm.complete(prompt)
        return self._parse_review_response(response)
    
    def _rule_based_review(self, config: Dict, user_intent: str) -> ValidationResult:
        """è¦å‰‡åŒ–èªç¾©å¯©æŸ¥ï¼ˆç„¡ LLM æ™‚ä½¿ç”¨ï¼‰"""
        issues = []
        
        components = config.get("components", [])
        connections = config.get("connections", [])
        
        # è¿½è¹¤è³‡æ–™æµ
        data_flow = self._trace_data_flow(components, connections)
        
        # æª¢æŸ¥è³‡æ–™çˆ†ç‚¸é¢¨éšª
        explosion_risk = self._check_data_explosion(data_flow)
        if explosion_risk:
            issues.append(explosion_risk)
        
        # ç”Ÿæˆ Mermaid åœ–
        mermaid = self._generate_mermaid(data_flow)
        
        max_risk = RiskLevel.INFO
        for issue in issues:
            if issue.get("risk") == "critical":
                max_risk = RiskLevel.CRITICAL
            elif issue.get("risk") == "warning" and max_risk != RiskLevel.CRITICAL:
                max_risk = RiskLevel.WARNING
        
        return ValidationResult(
            passed=max_risk != RiskLevel.CRITICAL,
            phase="semantic_review",
            issues=issues,
            risk_level=max_risk,
            data_flow_trace=mermaid
        )
    
    def _trace_data_flow(self, components: List[Dict], connections: List[Dict]) -> List[Dict]:
        """è¿½è¹¤è³‡æ–™æµ"""
        flow = []
        
        # å»ºç«‹çµ„ä»¶ ID â†’ è³‡è¨Šçš„æ˜ å°„
        comp_map = {c.get("id"): c for c in components}
        
        # ä¼°ç®—æ¯å€‹çµ„ä»¶çš„è¼¸å‡ºæ•¸é‡
        output_estimates = {}
        
        for comp in components:
            comp_id = comp.get("id")
            comp_type = comp.get("type", "")
            props = comp.get("properties", {})
            
            # ä¼°ç®—è¼¸å‡º
            if "box" in comp_type.lower() or "mesh" in comp_type.lower():
                # Mesh Box çš„è¼¸å‡º = X * Y * 6ï¼ˆå…­å€‹é¢ï¼‰
                x = props.get("x") or props.get("X") or props.get("default", 1)
                y = props.get("y") or props.get("Y") or 1
                z = props.get("z") or props.get("Z") or 1
                
                if isinstance(x, (int, float)) and x > 1:
                    output_estimates[comp_id] = int(x * y * 6)  # ç´°åˆ†å¾Œçš„é¢æ•¸
                else:
                    output_estimates[comp_id] = 6  # åŸºæœ¬ç«‹æ–¹é«”
            elif "slider" in comp_type.lower():
                output_estimates[comp_id] = 1
            elif "deconstruct" in comp_type.lower():
                # ç¹¼æ‰¿ä¸Šæ¸¸æ•¸é‡
                for conn in connections:
                    if conn.get("to_id") == comp_id:
                        upstream = output_estimates.get(conn.get("from_id"), 1)
                        output_estimates[comp_id] = upstream
                        break
            else:
                output_estimates[comp_id] = output_estimates.get(comp_id, 1)
        
        # å»ºç«‹æµç¨‹
        for comp in components:
            comp_id = comp.get("id")
            flow.append({
                "id": comp_id,
                "type": comp.get("type"),
                "nickname": comp.get("nickname", comp_id),
                "estimated_output": output_estimates.get(comp_id, 1)
            })
        
        return flow
    
    def _check_data_explosion(self, data_flow: List[Dict]) -> Optional[Dict]:
        """æª¢æŸ¥è³‡æ–™çˆ†ç‚¸é¢¨éšª"""
        for node in data_flow:
            estimated = node.get("estimated_output", 1)
            
            if estimated > 100:
                return {
                    "component": node.get("nickname"),
                    "type": node.get("type"),
                    "estimated_output": estimated,
                    "risk": "critical" if estimated > 500 else "warning",
                    "message": f"çµ„ä»¶ {node.get('nickname')} é ä¼°è¼¸å‡º {estimated} å€‹é …ç›®ï¼Œå¯èƒ½å°è‡´å¾ŒçºŒé‹ç®—é‡çˆ†ç‚¸"
                }
        
        return None
    
    def _generate_mermaid(self, data_flow: List[Dict]) -> str:
        """ç”Ÿæˆ Mermaid æµç¨‹åœ–"""
        lines = ["graph LR"]
        
        for i, node in enumerate(data_flow):
            node_id = node.get("id", f"node{i}")
            nickname = node.get("nickname", node_id)
            estimated = node.get("estimated_output", 1)
            
            # é¢¨éšªæ¨™è¨˜
            if estimated > 500:
                lines.append(f'    {node_id}["{nickname}<br/>âš ï¸ {estimated} items"]')
            elif estimated > 100:
                lines.append(f'    {node_id}["{nickname}<br/>âš¡ {estimated} items"]')
            else:
                lines.append(f'    {node_id}["{nickname}"]')
        
        return "\n".join(lines)
    
    def _build_review_prompt(self, config: Dict, user_intent: str) -> str:
        """å»ºç«‹ LLM å¯©æŸ¥ prompt"""
        return f"""
ä½ æ˜¯ Grasshopper èªç¾©å°ˆå®¶ã€‚è«‹å¯©æŸ¥ä»¥ä¸‹é…ç½®æ˜¯å¦æœƒå°è‡´å•é¡Œã€‚

## ç”¨æˆ¶æ„åœ–
{user_intent}

## é…ç½®
```json
{json.dumps(config, indent=2, ensure_ascii=False)[:2000]}
```

## è«‹æª¢æŸ¥
1. è³‡æ–™æµæ˜¯å¦æœƒçˆ†ç‚¸ï¼ˆæŒ‡æ•¸ç´šå¢é•·ï¼‰
2. åƒæ•¸èªç¾©æ˜¯å¦æ­£ç¢ºï¼ˆå¦‚ Mesh Box X/Y/Z æ˜¯ç´°åˆ†æ•¸é‡ä¸æ˜¯å°ºå¯¸ï¼‰
3. çµ„ä»¶é¸æ“‡æ˜¯å¦æ°ç•¶

## å›æ‡‰æ ¼å¼
```json
{{
    "passed": true/false,
    "risk_level": "info/warning/critical",
    "issues": [
        {{"component": "...", "message": "...", "risk": "..."}}
    ],
    "recommendation": "..."
}}
```
"""
    
    def _parse_review_response(self, response: str) -> ValidationResult:
        """è§£æ LLM å›æ‡‰"""
        try:
            # æå– JSON
            import re
            json_match = re.search(r'```json\s*(.*?)\s*```', response, re.DOTALL)
            if json_match:
                data = json.loads(json_match.group(1))
            else:
                data = json.loads(response)
            
            risk_map = {
                "info": RiskLevel.INFO,
                "warning": RiskLevel.WARNING,
                "critical": RiskLevel.CRITICAL
            }
            
            return ValidationResult(
                passed=data.get("passed", True),
                phase="semantic_review",
                issues=data.get("issues", []),
                risk_level=risk_map.get(data.get("risk_level", "info"), RiskLevel.INFO)
            )
        except Exception as e:
            return ValidationResult(
                passed=True,
                phase="semantic_review",
                issues=[{"message": f"LLM å›æ‡‰è§£æå¤±æ•—: {e}"}],
                risk_level=RiskLevel.WARNING
            )


# ============================================================================
# Main Executor
# ============================================================================

class WorkflowExecutor:
    """
    WorkflowExecutor v2.1 - çµ±ä¸€å…¥å£
    
    æ•´åˆï¼š
    - å…©éšæ®µ Router
    - Reference-First Workflow
    - Dual-Mode Fallback
    - å„ªåŒ–é©—è­‰é †åºï¼ˆPre-Check â†’ Semantic Reviewï¼‰
    """
    
    def __init__(
        self,
        reference_library_path: str = "reference_library",
        pattern_library_path: Optional[str] = None,
        mcp_client: Optional[Any] = None,
        llm_client: Optional[Any] = None,
        user_callback: Optional[Callable[[str], Awaitable[str]]] = None,
        auto_confirm: bool = False
    ):
        self.ref_path = Path(reference_library_path)
        self.pattern_path = Path(pattern_library_path) if pattern_library_path else None
        self.mcp = mcp_client
        self.llm = llm_client
        self.user_callback = user_callback
        self.auto_confirm = auto_confirm
        
        # åˆå§‹åŒ–çµ„ä»¶
        self.router = IntegratedRouter(
            reference_library_path=self.ref_path,
            pattern_library_path=self.pattern_path
        )
        self.pre_checker = PreExecutionChecker()
        self.semantic_reviewer = SemanticReviewer(llm_client=llm_client)

        # å­¸ç¿’ç³»çµ±
        config_dir = Path("config")
        self.knowledge_base = ConnectionKnowledgeBase(storage_dir=config_dir)
        self.learning_agent = LearningAgent(
            knowledge_base=self.knowledge_base,
            storage_dir=config_dir,
            auto_save=True
        )

        # å‡é™ç´šè¦å‰‡
        self.promotion_rules = {
            'min_usage': 3,
            'min_success_rate': 0.9,
        }
        self.demotion_rules = {
            'min_failures': 2,
            'or_success_rate_below': 0.7,
        }

        # Vision è¨ºæ–·æ•´åˆ
        self.vision_client = VisionDiagnosticClient()
        self.diagnostic_helper = ExecutionDiagnosticHelper(self.vision_client)
        self.enable_vision_diagnostic = True  # å¯é…ç½®é–‹é—œ

        # Component Validator (Validation-First Architecture)
        self.component_validator = ComponentValidator(config_dir=str(config_dir))
    
    async def run(self, user_request: str, context: Optional[Dict] = None) -> ExecutionResult:
        """
        ä¸»åŸ·è¡Œæµç¨‹
        
        Args:
            user_request: ç”¨æˆ¶è«‹æ±‚
            context: é¡å¤–ä¸Šä¸‹æ–‡
            
        Returns:
            ExecutionResult
        """
        context = context or {}
        
        print(f"\n{'='*60}")
        print(f"ğŸ“ ç”¨æˆ¶è«‹æ±‚: {user_request}")
        print(f"{'='*60}")
        
        # ========== Phase 1: Route ==========
        print(f"\nğŸ” Phase 1: è·¯ç”±...")
        decision = self.router.route(user_request, context)
        
        print(f"  æ¨¡å¼: {decision.mode.value}")
        print(f"  ä¿¡å¿ƒåº¦: {decision.confidence:.0%}")
        print(f"  éšæ®µ: {decision.stage}")
        print(f"  åŸå› : {decision.reason}")
        
        # ========== æ ¹æ“šæ¨¡å¼åŸ·è¡Œ ==========
        if decision.mode == ExecutionMode.REFERENCE:
            return await self._run_reference_mode(user_request, decision)
        elif decision.mode == ExecutionMode.WORKFLOW:
            return await self._run_workflow_mode(user_request, decision)
        else:
            return await self._run_meta_agent_mode(user_request, decision)
    
    async def _run_reference_mode(
        self, 
        user_request: str, 
        decision: RouterDecision
    ) -> ExecutionResult:
        """åŸ·è¡Œ Reference Mode"""
        
        reference = decision.reference
        if not reference:
            return ExecutionResult(
                success=False,
                mode=ExecutionMode.REFERENCE,
                phase=WorkflowPhase.SEARCH,
                errors=["Reference ä¸å­˜åœ¨"]
            )
        
        # ========== Phase 2: è¼‰å…¥é…ç½® ==========
        print(f"\nğŸ“‹ Phase 2: è¼‰å…¥ Golden Config: {reference['name']}")
        
        config_path = Path(reference['path'])
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
        except Exception as e:
            return ExecutionResult(
                success=False,
                mode=ExecutionMode.REFERENCE,
                phase=WorkflowPhase.SEARCH,
                errors=[f"è¼‰å…¥é…ç½®å¤±æ•—: {e}"]
            )
        
        # ========== Phase 3: ç¢ºèªï¼ˆHITLï¼‰==========
        if not self.auto_confirm:
            print(f"\nğŸ‘¤ Phase 3: ç­‰å¾…ç”¨æˆ¶ç¢ºèª...")
            confirmed = await self._ask_user_confirm(config, reference)
            if not confirmed:
                return ExecutionResult(
                    success=False,
                    mode=ExecutionMode.REFERENCE,
                    phase=WorkflowPhase.CONFIRM,
                    config_used=config,
                    errors=["ç”¨æˆ¶å–æ¶ˆ"]
                )
        
        # ========== Phase 3.5: Component Validationï¼ˆValidation-Firstï¼‰==========
        print(f"\nğŸ” Phase 3.5: Component Validation...")
        components = config.get("components", [])
        if components:
            comp_report = self.component_validator.validate_components(
                components, context=user_request
            )

            if not comp_report.can_proceed:
                print(f"  âš ï¸ éƒ¨åˆ†çµ„ä»¶éœ€è¦ç¢ºèª:")
                for comp_name in comp_report.requires_decision:
                    v = comp_report.get_validation(comp_name)
                    if v and v.status == ValidationStatus.AMBIGUOUS:
                        print(f"    â€¢ {comp_name}: æœ‰å¤šå€‹ç‰ˆæœ¬")
                    elif v and v.status == ValidationStatus.NOT_FOUND:
                        print(f"    â€¢ {comp_name}: æ‰¾ä¸åˆ°")

                # å¦‚æœä¸æ˜¯è‡ªå‹•ç¢ºèªæ¨¡å¼ï¼Œè¿”å›è®“ç”¨æˆ¶è™•ç†
                if not self.auto_confirm:
                    return ExecutionResult(
                        success=False,
                        mode=ExecutionMode.REFERENCE,
                        phase=WorkflowPhase.PRE_CHECK,
                        config_used=config,
                        component_validation=comp_report,
                        errors=["éƒ¨åˆ†çµ„ä»¶éœ€è¦ç¢ºèªï¼Œè«‹æŸ¥çœ‹ component_validation"]
                    )
            else:
                print(f"  âœ… {comp_report.valid_count} å€‹çµ„ä»¶å·²é©—è­‰")

        # ========== Phase 4: Pre-Checkï¼ˆå…ˆåšèªæ³•æª¢æŸ¥ï¼‰==========
        print(f"\nğŸ” Phase 4: Pre-Execution Checkï¼ˆèªæ³•ï¼‰...")
        pre_check_result = self.pre_checker.check(config)
        
        if pre_check_result.issues:
            print(f"  ç™¼ç¾ {len(pre_check_result.issues)} å€‹å•é¡Œ:")
            for issue in pre_check_result.issues:
                print(f"    â€¢ [{issue.get('risk', 'info')}] {issue.get('message', 'Unknown')}")
        
        if not pre_check_result.passed:
            print(f"  âŒ Pre-Check å¤±æ•—ï¼ˆCRITICAL å•é¡Œï¼‰")
            return ExecutionResult(
                success=False,
                mode=ExecutionMode.REFERENCE,
                phase=WorkflowPhase.PRE_CHECK,
                config_used=config,
                validation=pre_check_result,
                errors=[i.get("message", "Unknown") for i in pre_check_result.issues]
            )
        
        print(f"  âœ… Pre-Check é€šé")
        
        # ========== Phase 5: Semantic Reviewï¼ˆé€šéå¾Œå†åšèªç¾©å¯©æŸ¥ï¼‰==========
        print(f"\nğŸ§  Phase 5: Semantic Reviewï¼ˆèªç¾©ï¼‰...")
        semantic_result = await self.semantic_reviewer.review(config, user_request)
        
        if semantic_result.data_flow_trace:
            print(f"  è³‡æ–™æµè¿½è¹¤:")
            for line in semantic_result.data_flow_trace.split('\n')[:5]:
                print(f"    {line}")
        
        if semantic_result.issues:
            print(f"  ç™¼ç¾ {len(semantic_result.issues)} å€‹å•é¡Œ:")
            for issue in semantic_result.issues:
                print(f"    â€¢ [{issue.get('risk', 'info')}] {issue.get('message', 'Unknown')}")
        
        if not semantic_result.passed:
            print(f"  âŒ Semantic Review å¤±æ•—")
            
            # è©¢å•ç”¨æˆ¶æ˜¯å¦ç¹¼çºŒ
            if not self.auto_confirm:
                proceed = await self._ask_user_proceed_despite_warning(semantic_result)
                if not proceed:
                    return ExecutionResult(
                        success=False,
                        mode=ExecutionMode.REFERENCE,
                        phase=WorkflowPhase.SEMANTIC_REVIEW,
                        config_used=config,
                        validation=semantic_result,
                        errors=[i.get("message", "Unknown") for i in semantic_result.issues]
                    )
        
        print(f"  âœ… Semantic Review é€šé")
        
        # ========== Phase 6: Execute ==========
        print(f"\nğŸš€ Phase 6: åŸ·è¡Œ...")
        exec_result = await self._execute_config(config)

        if not exec_result["success"]:
            errors = exec_result.get("errors", [])
            diagnostic = None

            # ========== åŸ·è¡Œå¤±æ•—æ™‚èª¿ç”¨ Vision è¨ºæ–· ==========
            if self.enable_vision_diagnostic and errors:
                print(f"\nğŸ” åŸ·è¡Œå¤±æ•—ï¼Œèª¿ç”¨ Vision è¨ºæ–·...")
                diagnostic = self.diagnostic_helper.diagnose_execution_failure(
                    config=config,
                    errors=errors,
                    level=DiagnosticLevel.STANDARD
                )

                if diagnostic.get("diagnosed"):
                    print(f"  âœ… è¨ºæ–·å®Œæˆ")

                    # é¡¯ç¤ºè¨ºæ–·çµæœ
                    for diag in diagnostic.get("diagnostics", []):
                        if diag.get("ai_analyzed"):
                            print(f"  ğŸ’¡ åŸå› : {diag.get('cause', 'Unknown')}")
                            print(f"  ğŸ”§ å»ºè­°: {diag.get('solution', 'Unknown')}")

                            # è¨˜éŒ„å¤±æ•—åˆ° Archive
                            if diag.get("correct_params"):
                                print(f"  ğŸ“ æ­£ç¢ºåƒæ•¸: {diag.get('correct_params')}")
                else:
                    print(f"  âš ï¸ è¨ºæ–·å¤±æ•—: {diagnostic.get('error', 'Unknown')}")

            return ExecutionResult(
                success=False,
                mode=ExecutionMode.REFERENCE,
                phase=WorkflowPhase.EXECUTE,
                config_used=config,
                validation=semantic_result,
                errors=errors,
                diagnostic=diagnostic
            )
        
        # ========== Phase 7: Archive/Learn ==========
        print(f"\nğŸ“š Phase 7: æ­¸æª”èˆ‡å­¸ç¿’...")
        learned = await self._archive_and_learn(config_path, config, success=True)
        
        print(f"\n{'='*60}")
        print(f"âœ… åŸ·è¡ŒæˆåŠŸ")
        print(f"{'='*60}")
        
        return ExecutionResult(
            success=True,
            mode=ExecutionMode.REFERENCE,
            phase=WorkflowPhase.COMPLETE,
            config_used=config,
            validation=semantic_result,
            learned=learned
        )
    
    async def _run_workflow_mode(
        self, 
        user_request: str, 
        decision: RouterDecision
    ) -> ExecutionResult:
        """åŸ·è¡Œ Workflow Modeï¼ˆä¸‰ç¶­è©•ä¼°é€šéä½†ç„¡ Golden Configï¼‰"""
        
        print(f"\nâš™ï¸ Workflow Modeï¼ˆä¸‰ç¶­è©•ä¼°é€šéï¼‰")
        
        # å¦‚æœæœ‰éƒ¨åˆ†åŒ¹é…çš„ Referenceï¼Œå˜—è©¦ä½¿ç”¨
        if decision.reference:
            print(f"  å˜—è©¦ä½¿ç”¨éƒ¨åˆ†åŒ¹é…: {decision.reference['name']}")
            return await self._run_reference_mode(user_request, decision)
        
        # å¦å‰‡éœ€è¦ç”Ÿæˆæ–°é…ç½®
        print(f"  âš ï¸ æ²’æœ‰åŒ¹é…çš„ Referenceï¼Œéœ€è¦ç”Ÿæˆæ–°é…ç½®")
        print(f"  TODO: æ•´åˆ Dual-Mode Workflow çš„ç”Ÿæˆé‚è¼¯")
        
        return ExecutionResult(
            success=False,
            mode=ExecutionMode.WORKFLOW,
            phase=WorkflowPhase.SEARCH,
            errors=["Workflow Mode é…ç½®ç”Ÿæˆå°šæœªå¯¦ä½œ"]
        )
    
    async def _run_meta_agent_mode(
        self, 
        user_request: str, 
        decision: RouterDecision
    ) -> ExecutionResult:
        """åŸ·è¡Œ Meta-Agent Mode"""
        
        print(f"\nğŸ” Meta-Agent Mode")
        print(f"  åŸå› : {decision.reason}")
        
        # å¦‚æœæœ‰éƒ¨åˆ†åŒ¹é…ï¼Œè©¢å•ç”¨æˆ¶
        if decision.partial_matches:
            print(f"\nğŸ“š æ‰¾åˆ° {len(decision.partial_matches)} å€‹éƒ¨åˆ†åŒ¹é…:")
            for i, match in enumerate(decision.partial_matches):
                print(f"  [{i+1}] {match['name']} ({match['confidence']:.0%})")
            
            if not self.auto_confirm:
                choice = await self._ask_user_select_or_create(decision.partial_matches)
                
                if choice and choice != "create":
                    # ç”¨æˆ¶é¸æ“‡äº†ä¸€å€‹åŒ¹é…
                    selected = decision.partial_matches[int(choice) - 1]
                    decision.reference = selected
                    return await self._run_reference_mode(user_request, decision)
        
        print(f"\n  âš ï¸ Meta-Agent å‰µå»ºåŠŸèƒ½å°šæœªæ•´åˆ")
        print(f"  TODO: æ•´åˆ ask_user, search_tool, create_tool")
        
        return ExecutionResult(
            success=False,
            mode=ExecutionMode.META_AGENT,
            phase=WorkflowPhase.SEARCH,
            errors=["Meta-Agent å‰µå»ºåŠŸèƒ½å°šæœªæ•´åˆ"]
        )
    
    async def _ask_user_confirm(self, config: Dict, reference: Dict) -> bool:
        """è©¢å•ç”¨æˆ¶ç¢ºèª"""
        meta = config.get("_meta", {})
        components = config.get("components", [])
        
        message = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ“‹ Golden Config: {reference['name']:<46} â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  çµ„ä»¶æ•¸: {len(components):<60} â•‘
â•‘  ä¿¡å¿ƒåº¦: {reference['confidence']:.0%:<60} â•‘
â•‘  é©—è­‰: {'âœ… å·²é©—è­‰' if meta.get('verified') else 'âš ï¸ æœªé©—è­‰':<60} â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ç¢ºèªä½¿ç”¨æ­¤é…ç½®ï¼Ÿ[Y/n]
"""
        
        if self.user_callback:
            response = await self.user_callback(message)
            return response.lower() in ['', 'y', 'yes', 'æ˜¯', 'ç¢ºèª']
        else:
            print(message)
            return True  # ç„¡å›èª¿æ™‚é»˜èªç¢ºèª
    
    async def _ask_user_proceed_despite_warning(self, validation: ValidationResult) -> bool:
        """è©¢å•ç”¨æˆ¶æ˜¯å¦å¿½ç•¥è­¦å‘Šç¹¼çºŒ"""
        message = f"""
âš ï¸ Semantic Review ç™¼ç¾å•é¡Œï¼š

{chr(10).join(f"  â€¢ {i.get('message', 'Unknown')}" for i in validation.issues)}

ä»è¦ç¹¼çºŒåŸ·è¡Œå—ï¼Ÿ[y/N]
"""
        
        if self.user_callback:
            response = await self.user_callback(message)
            return response.lower() in ['y', 'yes', 'æ˜¯']
        else:
            print(message)
            return False  # ç„¡å›èª¿æ™‚é»˜èªä¸ç¹¼çºŒ
    
    async def _ask_user_select_or_create(self, matches: List[Dict]) -> Optional[str]:
        """è©¢å•ç”¨æˆ¶é¸æ“‡åŒ¹é…æˆ–å‰µå»ºæ–°é…ç½®"""
        message = f"""
è«‹é¸æ“‡ï¼š
{chr(10).join(f"  [{i+1}] {m['name']} ({m['confidence']:.0%})" for i, m in enumerate(matches))}
  [c] å‰µå»ºæ–°é…ç½®

è¼¸å…¥é¸æ“‡ï¼š
"""
        
        if self.user_callback:
            response = await self.user_callback(message)
            if response.lower() == 'c':
                return "create"
            if response.isdigit() and 1 <= int(response) <= len(matches):
                return response
            return None
        else:
            print(message)
            return "1" if matches else "create"
    
    async def _execute_config(self, config: Dict) -> Dict:
        """åŸ·è¡Œé…ç½®"""
        
        if self.mcp is None:
            # æ¨¡æ“¬åŸ·è¡Œ
            print("  âš ï¸ ç„¡ MCP Clientï¼Œæ¨¡æ“¬åŸ·è¡Œ")
            
            components = config.get("components", [])
            connections = config.get("connections", [])
            
            for comp in components[:5]:
                print(f"    â• add_component({comp.get('type')})")
            
            if len(components) > 5:
                print(f"    ... é‚„æœ‰ {len(components) - 5} å€‹çµ„ä»¶")
            
            print(f"    ğŸ”— å»ºç«‹ {len(connections)} æ¢é€£æ¥")
            
            return {"success": True}
        
        # å¯¦éš›åŸ·è¡Œ
        try:
            # TODO: æ•´åˆ MCP åŸ·è¡Œé‚è¼¯
            return {"success": True}
        except Exception as e:
            return {"success": False, "errors": [str(e)]}
    
    async def _archive_and_learn(
        self,
        config_path: Path,
        config: Dict,
        success: bool,
        diagnostic: Optional[Dict] = None
    ) -> bool:
        """
        æ­¸æª”èˆ‡å­¸ç¿’

        æ•´åˆ Learning Agentï¼š
        - æˆåŠŸåŸ·è¡Œï¼šå¾é…ç½®ä¸­å­¸ç¿’é€£æ¥æ¨¡å¼
        - å¤±æ•—åŸ·è¡Œï¼šè¨˜éŒ„è¨ºæ–·çµæœï¼Œä¾›å¾ŒçºŒå­¸ç¿’
        - æ›´æ–° connection_triplets.json
        - è‡ªå‹•ä¿å­˜åˆ° config/ ç›®éŒ„
        """

        try:
            # æ›´æ–°ä½¿ç”¨çµ±è¨ˆ
            stats = config.get("_stats", {"usage_count": 0, "success_count": 0})
            stats["usage_count"] = stats.get("usage_count", 0) + 1

            if success:
                stats["success_count"] = stats.get("success_count", 0) + 1

            stats["last_used"] = datetime.now().isoformat()
            config["_stats"] = stats

            # ========== Learning Agent å­¸ç¿’ ==========
            if success:
                execution_report = {"status": "success"}
                context = f"Reference: {config.get('_meta', {}).get('name', config_path.stem)}"

                learning_result = self.learning_agent.learn_from_execution(
                    workflow_json=config,
                    execution_report=execution_report,
                    context=context
                )

                if learning_result.get("learned_count", 0) > 0:
                    print(f"  ğŸ§  å­¸ç¿’åˆ° {learning_result['learned_count']} å€‹é€£æ¥æ¨¡å¼")
                    if learning_result.get("new_patterns"):
                        print(f"     æ–°æ¨¡å¼: {learning_result['new_patterns'][:3]}")

            # ========== å¤±æ•—æ™‚è¨˜éŒ„è¨ºæ–·çµæœ ==========
            if not success and diagnostic and diagnostic.get("diagnosed"):
                # è¨˜éŒ„å¤±æ•—è¨ºæ–·åˆ°é…ç½®çš„ _failures æ¬„ä½
                failures = config.get("_failures", [])
                failure_record = {
                    "timestamp": datetime.now().isoformat(),
                    "diagnostics": diagnostic.get("diagnostics", []),
                    "patterns_learned": diagnostic.get("patterns", []),
                    "suggestions": diagnostic.get("suggestions", [])
                }
                failures.append(failure_record)

                # ä¿ç•™æœ€è¿‘ 10 æ¬¡å¤±æ•—è¨˜éŒ„
                config["_failures"] = failures[-10:]

                print(f"  ğŸ“ è¨˜éŒ„å¤±æ•—è¨ºæ–·ï¼ˆå…± {len(config['_failures'])} æ¢è¨˜éŒ„ï¼‰")

                # å¦‚æœå¤±æ•—æ¬¡æ•¸éå¤šï¼Œæ¨™è¨˜ç‚ºéœ€è¦å¯©æŸ¥
                if len(failures) >= self.demotion_rules['min_failures']:
                    print(f"  âš ï¸ å¤±æ•—æ¬¡æ•¸é”åˆ° {len(failures)}ï¼Œå»ºè­°å¯©æŸ¥é…ç½®")
                    config["_needs_review"] = True

            # æª¢æŸ¥æ˜¯å¦æ‡‰è©²å‡ç´šï¼ˆå¾ variation åˆ° goldenï¼‰
            success_rate = stats["success_count"] / stats["usage_count"]

            if (stats["usage_count"] >= self.promotion_rules['min_usage'] and
                success_rate >= self.promotion_rules['min_success_rate']):

                if "variation" in str(config_path):
                    print(f"  ğŸ‰ é”åˆ°å‡ç´šæ¢ä»¶ï¼ï¼ˆä½¿ç”¨ {stats['usage_count']} æ¬¡ï¼ŒæˆåŠŸç‡ {success_rate:.0%}ï¼‰")
                    # TODO: å¯¦ä½œå‡ç´šé‚è¼¯

            # å„²å­˜æ›´æ–°
            with open(config_path, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)

            return True

        except Exception as e:
            print(f"  âš ï¸ æ­¸æª”å¤±æ•—: {e}")
            return False


# ============================================================================
# CLI
# ============================================================================

async def main():
    """æ¸¬è©¦å…¥å£"""
    import sys
    
    test_cases = [
        "åšä¸€å€‹ WASP ç«‹æ–¹é«”èšé›†",
        "åšä¸€å€‹ WASP é›¢æ•£è¨­è¨ˆ",
        "åšä¸€å€‹ Karamba çµæ§‹åˆ†æ",
        "åšå€‹æ±è¥¿",
    ]
    
    if len(sys.argv) > 1:
        test_cases = [" ".join(sys.argv[1:])]
    
    # å»ºç«‹æ¸¬è©¦ç”¨çš„ reference_library
    test_ref_path = Path("/home/claude/gh_mcp_integrated/reference_library")
    test_ref_path.mkdir(parents=True, exist_ok=True)
    
    # è¤‡è£½ Golden Config
    import shutil
    src = Path("/mnt/user-data/outputs/gh_mcp_reference_first/reference_library")
    if src.exists():
        shutil.copytree(src, test_ref_path, dirs_exist_ok=True)
    
    executor = WorkflowExecutor(
        reference_library_path=str(test_ref_path),
        auto_confirm=True
    )
    
    for request in test_cases:
        result = await executor.run(request)
        print(f"\næœ€çµ‚çµæœ: {'âœ… æˆåŠŸ' if result.success else 'âŒ å¤±æ•—'} ({result.mode.value})")
        print()


if __name__ == "__main__":
    asyncio.run(main())
