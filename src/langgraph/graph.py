"""
LangGraph Graph Definition
==========================
å®šç¾©å®Œæ•´çš„ LangGraph æµç¨‹åœ–çµæ§‹
"""

from typing import Dict, Any, Callable, Optional
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

from .graph_state import GraphState, create_initial_state, state_summary
from .nodes import (
    parse_intent,
    generate_mermaid,
    generate_gh_code,
    evaluate_elegance,
    error_handler
)


def should_continue(state: GraphState) -> str:
    """
    æ¢ä»¶é‚Šç•Œå‡½æ•¸ï¼šæ±ºå®šä¸‹ä¸€æ­¥å‹•ä½œ
    
    Returns:
        ä¸‹ä¸€å€‹ç¯€é»çš„åç¨±
    """
    next_action = state.get("next_action", "accept")
    
    # æª¢æŸ¥éŒ¯èª¤ç‹€æ…‹
    if state.get("has_error", False):
        return "end"
    
    # æ ¹æ“šè©•ä¼°çµæœæ±ºå®šä¸‹ä¸€æ­¥
    if next_action == "accept":
        return "end"
    elif next_action == "refine_intent":
        return "parse_intent"
    elif next_action == "refine_mermaid":
        return "generate_mermaid"
    elif next_action == "refine_gh":
        return "generate_gh_code"
    else:
        return "end"


def build_graph(
    with_checkpointing: bool = False,
    custom_nodes: Optional[Dict[str, Callable]] = None
) -> StateGraph:
    """
    å»ºæ§‹ LangGraph æµç¨‹åœ–
    
    Args:
        with_checkpointing: æ˜¯å¦å•Ÿç”¨æª¢æŸ¥é»ï¼ˆæ”¯æ´æš«åœ/æ¢å¾©ï¼‰
        custom_nodes: è‡ªå®šç¾©ç¯€é»å‡½æ•¸è¦†è“‹
        
    Returns:
        ç·¨è­¯å¾Œçš„ StateGraph
    """
    # åˆå§‹åŒ–åœ–
    workflow = StateGraph(GraphState)
    
    # å–å¾—ç¯€é»å‡½æ•¸ï¼ˆæ”¯æ´è‡ªå®šç¾©è¦†è“‹ï¼‰
    nodes = {
        "parse_intent": parse_intent,
        "generate_mermaid": generate_mermaid,
        "generate_gh_code": generate_gh_code,
        "evaluate_elegance": evaluate_elegance,
        "error_handler": error_handler,
    }
    
    if custom_nodes:
        nodes.update(custom_nodes)
    
    # æ·»åŠ ç¯€é»
    workflow.add_node("parse_intent", nodes["parse_intent"])
    workflow.add_node("generate_mermaid", nodes["generate_mermaid"])
    workflow.add_node("generate_gh_code", nodes["generate_gh_code"])
    workflow.add_node("evaluate_elegance", nodes["evaluate_elegance"])
    workflow.add_node("error_handler", nodes["error_handler"])
    
    # è¨­å®šå…¥å£é»
    workflow.set_entry_point("parse_intent")
    
    # æ·»åŠ å›ºå®šé‚Šç•Œï¼ˆç·šæ€§æµç¨‹éƒ¨åˆ†ï¼‰
    workflow.add_edge("parse_intent", "generate_mermaid")
    workflow.add_edge("generate_mermaid", "generate_gh_code")
    workflow.add_edge("generate_gh_code", "evaluate_elegance")
    
    # æ·»åŠ æ¢ä»¶é‚Šç•Œï¼ˆè¿´åœˆæ ¸å¿ƒï¼‰
    workflow.add_conditional_edges(
        "evaluate_elegance",
        should_continue,
        {
            "end": END,
            "parse_intent": "parse_intent",
            "generate_mermaid": "generate_mermaid",
            "generate_gh_code": "generate_gh_code",
        }
    )
    
    # éŒ¯èª¤è™•ç†é‚Šç•Œ
    workflow.add_edge("error_handler", END)
    
    # ç·¨è­¯åœ–
    if with_checkpointing:
        memory = MemorySaver()
        return workflow.compile(checkpointer=memory)
    else:
        return workflow.compile()


def run_generation(
    design_intent: str,
    constraints: Optional[list] = None,
    max_iterations: int = 5,
    acceptance_threshold: float = 0.8,
    verbose: bool = True,
    stream: bool = False
) -> Dict[str, Any]:
    """
    åŸ·è¡Œå®Œæ•´çš„ç”Ÿæˆæµç¨‹
    
    Args:
        design_intent: è¨­è¨ˆæ„åœ–æè¿°
        constraints: é™„åŠ ç´„æŸæ¢ä»¶
        max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•¸
        acceptance_threshold: å„ªé›…åº¦æ¥å—é–¾å€¼
        verbose: æ˜¯å¦è¼¸å‡ºéç¨‹è³‡è¨Š
        stream: æ˜¯å¦ä½¿ç”¨ä¸²æµæ¨¡å¼
        
    Returns:
        æœ€çµ‚ç‹€æ…‹å­—å…¸
    """
    # å»ºç«‹åˆå§‹ç‹€æ…‹
    initial_state = create_initial_state(
        design_intent=design_intent,
        constraints=constraints,
        max_iterations=max_iterations,
        acceptance_threshold=acceptance_threshold
    )
    
    # å»ºç«‹ä¸¦ç·¨è­¯åœ–
    graph = build_graph()
    
    if verbose:
        print("=" * 60)
        print("ğŸš€ Starting Grasshopper Code Generation")
        print("=" * 60)
        print(f"Design Intent: {design_intent}")
        print(f"Max Iterations: {max_iterations}")
        print(f"Acceptance Threshold: {acceptance_threshold}")
        print("=" * 60)
    
    if stream:
        # ä¸²æµæ¨¡å¼ - é€æ­¥è¼¸å‡º
        final_state = None
        for event in graph.stream(initial_state):
            for node_name, node_state in event.items():
                if verbose:
                    print(f"\nğŸ“ Node: {node_name}")
                    if node_state.get("elegance_score"):
                        print(f"   Score: {node_state['elegance_score']:.3f}")
                    if node_state.get("next_action"):
                        print(f"   Next: {node_state['next_action']}")
                final_state = node_state
        result = final_state
    else:
        # æ‰¹æ¬¡æ¨¡å¼ - ä¸€æ¬¡å®Œæˆ
        result = graph.invoke(initial_state)
    
    if verbose:
        print("\n" + "=" * 60)
        print("âœ… Generation Complete")
        print("=" * 60)
        print(state_summary(result))
    
    return result


def run_generation_async(
    design_intent: str,
    constraints: Optional[list] = None,
    **kwargs
):
    """
    éåŒæ­¥åŸ·è¡Œç”Ÿæˆæµç¨‹ï¼ˆç”¨æ–¼èˆ‡ MCP æ•´åˆï¼‰
    """
    import asyncio
    
    async def _run():
        return run_generation(design_intent, constraints, **kwargs)
    
    return asyncio.run(_run())


# ============================================================
# è¦–è¦ºåŒ–å·¥å…·
# ============================================================

def visualize_graph():
    """
    ç”¢ç”Ÿæµç¨‹åœ–çš„ Mermaid è¦–è¦ºåŒ–
    
    Returns:
        Mermaid æ ¼å¼çš„æµç¨‹åœ–ä»£ç¢¼
    """
    return """
```mermaid
graph TD
    START((é–‹å§‹)) --> PI[parse_intent<br/>æ„åœ–è§£æ]
    PI --> GM[generate_mermaid<br/>ç”Ÿæˆæµç¨‹åœ–]
    GM --> GC[generate_gh_code<br/>ç”Ÿæˆ GH Code]
    GC --> EE[evaluate_elegance<br/>å„ªé›…åº¦è©•ä¼°]
    
    EE -->|score >= threshold| ACCEPT((æ¥å—))
    EE -->|refine_intent| PI
    EE -->|refine_mermaid| GM
    EE -->|refine_gh| GC
    EE -->|max_iterations| ACCEPT
    
    style PI fill:#e1f5fe
    style GM fill:#fff3e0
    style GC fill:#e8f5e9
    style EE fill:#fce4ec
    style ACCEPT fill:#c8e6c9
```
"""


def export_graph_png(output_path: str = "graph.png"):
    """
    åŒ¯å‡ºæµç¨‹åœ–ç‚º PNGï¼ˆéœ€è¦ graphvizï¼‰
    """
    try:
        graph = build_graph()
        # LangGraph æä¾›çš„è¦–è¦ºåŒ–åŠŸèƒ½
        png_data = graph.get_graph().draw_mermaid_png()
        with open(output_path, "wb") as f:
            f.write(png_data)
        return output_path
    except Exception as e:
        print(f"ç„¡æ³•åŒ¯å‡º PNG: {e}")
        print("è«‹ç¢ºä¿å®‰è£äº† graphviz å’Œ pygraphviz")
        return None


# ============================================================
# CLI æ¸¬è©¦å…¥å£
# ============================================================

if __name__ == "__main__":
    # æ¸¬è©¦ç¯„ä¾‹
    test_intents = [
        "å‰µå»ºä¸€å€‹å¯èª¿æ•´çš„èºæ—‹æ¨“æ¢¯ï¼Œè¦èƒ½æ§åˆ¶åœˆæ•¸ã€åŠå¾‘å’Œé«˜åº¦",
        "æ²¿è‘—æ›²ç·šå‡å‹»åˆ†å¸ƒæ–¹å¡Šï¼Œæ•¸é‡å’Œé–“è·å¯èª¿",
        "ç”Ÿæˆä¸€å€‹åƒæ•¸åŒ–çš„ç©¿å­”è¡¨çš®",
    ]
    
    print("\nğŸ§ª Testing LangGraph Pipeline\n")
    
    result = run_generation(
        design_intent=test_intents[0],
        max_iterations=3,
        acceptance_threshold=0.7,
        verbose=True,
        stream=True
    )
    
    print("\nğŸ“Š Final GH Code:")
    if result.get("gh_code"):
        import json
        print(json.dumps(result["gh_code"], indent=2, ensure_ascii=False))
